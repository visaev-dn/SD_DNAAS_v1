#!/usr/bin/env python3
"""
Lab Automation Framework - Flask API Server
Provides REST API endpoints and WebSocket support for the frontend integration.
"""

import os
import sys
import json
import yaml
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any
import time # Added for time.time()

from flask import Flask, jsonify, request, send_file, current_app
from flask_cors import CORS
from flask_socketio import SocketIO, emit, join_room, leave_room
from flask_sqlalchemy import SQLAlchemy

# Add current directory to path for imports
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Import database models and authentication
from models import db, User, Configuration, AuditLog, UserVlanAllocation, UserPermission, PersonalBridgeDomain, TopologyScan
from auth import token_required, permission_required, admin_required, user_ownership_required, create_audit_log
from database_manager import DatabaseManager
from deployment_manager import DeploymentManager

# Import existing modules
from config_engine.unified_bridge_domain_builder import UnifiedBridgeDomainBuilder
from config_engine.device_scanner import DeviceScanner
from scripts.ssh_push_menu import SSHPushMenu
from scripts.inventory_manager import InventoryManager
from scripts.device_status_viewer import DeviceStatusViewer

# Import the enhanced topology scanner
from config_engine.enhanced_topology_scanner import EnhancedTopologyScanner

# Import smart deployment components
from config_engine.smart_deployment_manager import SmartDeploymentManager
from config_engine.configuration_diff_engine import ConfigurationDiffEngine
from config_engine.rollback_manager import RollbackManager
from config_engine.validation_framework import ValidationFramework

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Version tracking
VERSION = "1.0.2"
logger.info(f"üöÄ Starting Lab Automation API Server v{VERSION}")

# Initialize Flask app
app = Flask(__name__)
app.config['SECRET_KEY'] = os.getenv('SECRET_KEY', 'lab-automation-secret-key-2024')
app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///lab_automation.db'
app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False

# Initialize database
db.init_app(app)

# Lightweight migration: ensure new Configuration columns exist in SQLite
def _ensure_configuration_columns():
    try:
        with app.app_context():
            # Create tables if not present
            db.create_all()
            from sqlalchemy import text
            conn = db.session.connection()
            cols = conn.execute(text("PRAGMA table_info('configurations')")).fetchall()
            existing = {row[1] for row in cols}  # name is index 1

            to_add = []
            if 'config_source' not in existing:
                to_add.append("ADD COLUMN config_source VARCHAR(50)")
            if 'builder_type' not in existing:
                to_add.append("ADD COLUMN builder_type VARCHAR(50)")
            if 'topology_type' not in existing:
                to_add.append("ADD COLUMN topology_type VARCHAR(50)")
            if 'derived_from_scan_id' not in existing:
                to_add.append("ADD COLUMN derived_from_scan_id INTEGER")
            if 'builder_input' not in existing:
                to_add.append("ADD COLUMN builder_input TEXT")

            for clause in to_add:
                try:
                    conn.execute(text(f"ALTER TABLE configurations {clause}"))
                except Exception as e:
                    logger.warning(f"Migration step failed ({clause}): {e}")
            if to_add:
                db.session.commit()
                logger.info(f"Applied configuration column migration: {to_add}")
            else:
                logger.info("Configuration table up to date; no migration needed")
    except Exception as e:
        logger.error(f"Migration error: {e}")

_ensure_configuration_columns()

# Initialize database manager
db_manager = DatabaseManager()

CORS(app, origins=["http://localhost:3000", "http://localhost:5173", "http://localhost:8080"])

# Initialize SocketIO
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# Initialize deployment manager
deployment_manager = DeploymentManager(socketio)

# Global instances
builder = UnifiedBridgeDomainBuilder()
inventory_manager = InventoryManager()
device_viewer = DeviceStatusViewer()
device_scanner = DeviceScanner()

# Initialize smart deployment components
smart_deployment_manager = SmartDeploymentManager(
    topology_dir="topology",
    deployment_manager=deployment_manager
)
# Note: ConfigurationDiffEngine, RollbackManager, and ValidationFramework are 
# already initialized within SmartDeploymentManager, so we don't need separate instances

# ============================================================================
# ENHANCED DATABASE API INTEGRATION
# ============================================================================

# Initialize Enhanced Database API integration
try:
    from config_engine.phase1_api import enable_enhanced_database_api
    from config_engine.phase1_database import create_phase1_database_manager
    
    # Create enhanced database manager
    enhanced_db_manager = create_phase1_database_manager()
    
    # Enable enhanced database API integration
    enhanced_api_enabled = enable_enhanced_database_api(app, enhanced_db_manager)
    
    if enhanced_api_enabled:
        logger.info("üöÄ Enhanced Database API integration enabled successfully")
        logger.info("üì° Enhanced Database endpoints available at /api/enhanced-database/*")
        
        # Add Enhanced Database health check endpoint
        @app.route('/api/enhanced-database/health', methods=['GET'])
        def enhanced_database_health_check():
            """Enhanced Database API health check endpoint"""
            try:
                from config_engine.phase1_api import EnhancedDatabaseAPIRouter
                
                # Get health status from Enhanced Database router
                router = EnhancedDatabaseAPIRouter(app, enhanced_db_manager)
                health_status = router.health_check()
                
                return jsonify({
                    "success": True,
                    "enhanced_database": True,
                    "health_status": health_status,
                    "endpoints": {
                        "topologies": "/api/enhanced-database/topologies",
                        "devices": "/api/enhanced-database/devices", 
                        "interfaces": "/api/enhanced-database/interfaces",
                        "paths": "/api/enhanced-database/paths",
                        "bridge_domains": "/api/enhanced-database/bridge-domains",
                        "migration": "/api/enhanced-database/migrate",
                        "export": "/api/enhanced-database/export"
                    }
                })
                
            except Exception as e:
                logger.error(f"Enhanced Database health check failed: {e}")
                return jsonify({
                    "success": False,
                    "enhanced_database": True,
                    "error": str(e)
                }), 500
        
        # Add Enhanced Database status endpoint
        @app.route('/api/enhanced-database/status', methods=['GET'])
        def enhanced_database_status():
            """Get Enhanced Database integration status and capabilities"""
            try:
                db_info = enhanced_db_manager.get_database_info()
                
                return jsonify({
                    "success": True,
                    "enhanced_database_integration": {
                        "status": "active",
                        "version": "1.0.0",
                        "database": {
                            "status": "ready" if db_info.get('phase1_tables') else "not_initialized",
                            "tables": db_info.get('phase1_tables', []),
                            "total_records": db_info.get('total_phase1_records', 0),
                            "database_size": db_info.get('database_size', 0)
                        },
                        "capabilities": {
                            "topology_management": True,
                            "device_management": True,
                            "interface_management": True,
                            "path_management": True,
                            "bridge_domain_management": True,
                            "data_export_import": True,
                            "legacy_migration": True
                        }
                    }
                })
                
            except Exception as e:
                logger.error(f"Enhanced Database status check failed: {e}")
                return jsonify({
                    "success": False,
                    "error": str(e)
                }), 500
        
        logger.info("‚úÖ Enhanced Database API endpoints integrated successfully")
        
    else:
        logger.warning("‚ö†Ô∏è Enhanced Database API integration failed - continuing without enhanced features")
        enhanced_db_manager = None
        
except Exception as e:
    logger.error(f"‚ùå Failed to initialize Enhanced Database API integration: {e}")
    logger.info("üîÑ Continuing without enhanced features - legacy functionality preserved")
    enhanced_db_manager = None

# ============================================================================
# AUTHENTICATION ENDPOINTS
# ============================================================================

@app.route('/api/auth/register', methods=['POST'])
def register():
    """User registration endpoint"""
    try:
        data = request.get_json()
        username = data.get('username', '').strip()
        email = data.get('email', '').strip()
        password = data.get('password', '')
        
        # Validate required fields
        if not username or not email or not password:
            return jsonify({
                "success": False,
                "error": "Username, email, and password are required"
            }), 400
        
        # Check if user already exists
        if User.query.filter_by(username=username).first():
            return jsonify({
                "success": False,
                "error": "Username already exists"
            }), 409
        
        if User.query.filter_by(email=email).first():
            return jsonify({
                "success": False,
                "error": "Email already exists"
            }), 409
        
        # Create new user (default role is 'user')
        new_user = User(username=username, email=email, password=password)
        db.session.add(new_user)
        db.session.commit()
        
        # Create user directories
        from auth import ensure_user_directories
        ensure_user_directories(new_user.id)
        
        # Create audit log
        create_audit_log(new_user.id, 'register', 'user', new_user.id, {
            'username': username,
            'email': email,
            'role': new_user.role
        })
        
        return jsonify({
            "success": True,
            "message": "User registered successfully",
            "user": new_user.to_dict()
        }), 201
        
    except Exception as e:
        logger.error(f"Registration error: {e}")
        return jsonify({
            "success": False,
            "error": "Registration failed"
        }), 500

@app.route('/api/auth/login', methods=['POST'])
def login():
    """User login endpoint"""
    try:
        data = request.get_json()
        username = data.get('username', '').strip()
        password = data.get('password', '')
        
        if not username or not password:
            return jsonify({
                "success": False,
                "error": "Username and password are required"
            }), 400
        
        # Find user
        user = User.query.filter_by(username=username).first()
        
        if not user or not user.check_password(password):
            return jsonify({
                "success": False,
                "error": "Invalid username or password"
            }), 401
        
        if not user.is_active:
            return jsonify({
                "success": False,
                "error": "Account is deactivated"
            }), 401
        
        # Update last login
        user.last_login = datetime.utcnow()
        db.session.commit()
        
        # Generate JWT token
        token = user.generate_token()
        
        # Create audit log
        create_audit_log(user.id, 'login', 'user', user.id, {
            'username': username,
            'ip_address': request.remote_addr
        })
        
        return jsonify({
            "success": True,
            "message": "Login successful",
            "token": token,
            "user": user.to_dict()
        })
        
    except Exception as e:
        logger.error(f"Login error: {e}")
        return jsonify({
            "success": False,
            "error": "Login failed"
        }), 500

@app.route('/api/auth/logout', methods=['POST'])
@token_required
def logout(current_user):
    """User logout endpoint"""
    try:
        # Create audit log
        create_audit_log(current_user.id, 'logout', 'user', current_user.id, {
            'username': current_user.username
        })
        
        return jsonify({
            "success": True,
            "message": "Logout successful"
        })
        
    except Exception as e:
        logger.error(f"Logout error: {e}")
        return jsonify({
            "success": False,
            "error": "Logout failed"
        }), 500

@app.route('/api/auth/refresh', methods=['POST'])
@token_required
def refresh_token(current_user):
    """Refresh JWT token"""
    try:
        # Generate new token
        new_token = current_user.generate_token()
        
        return jsonify({
            "success": True,
            "token": new_token,
            "user": current_user.to_dict()
        })
        
    except Exception as e:
        logger.error(f"Token refresh error: {e}")
        return jsonify({
            "success": False,
            "error": "Token refresh failed"
        }), 500

@app.route('/api/auth/me', methods=['GET'])
@token_required
def get_current_user(current_user):
    """Get current user information"""
    return jsonify({
        "success": True,
        "user": current_user.to_dict()
    })

@app.route('/api/auth/change-password', methods=['POST'])
@token_required
def change_password(current_user):
    """Change user password"""
    try:
        data = request.get_json()
        current_password = data.get('currentPassword', '')
        new_password = data.get('newPassword', '')
        
        if not current_password or not new_password:
            return jsonify({
                "success": False,
                "error": "Current password and new password are required"
            }), 400
        
        # Verify current password
        if not current_user.check_password(current_password):
            return jsonify({
                "success": False,
                "error": "Current password is incorrect"
            }), 401
        
        # Validate new password strength
        from auth import validate_password_strength
        is_valid, message = validate_password_strength(new_password)
        if not is_valid:
            return jsonify({
                "success": False,
                "error": message
            }), 400
        
        # Update password
        current_user.set_password(new_password)
        db.session.commit()
        
        # Create audit log
        create_audit_log(current_user.id, 'change_password', 'user', current_user.id, {
            'username': current_user.username
        })
        
        return jsonify({
            "success": True,
            "message": "Password changed successfully"
        })
        
    except Exception as e:
        logger.error(f"Change password error: {e}")
        return jsonify({
            "success": False,
            "error": "Password change failed"
        }), 500

@app.route('/api/test/db', methods=['GET'])
def test_database():
    """Test database connectivity"""
    try:
        users = User.query.all()
        return jsonify({
            "success": True,
            "message": "Database connection successful",
            "user_count": len(users),
            "users": [{"username": u.username, "role": u.role} for u in users]
        })
    except Exception as e:
        logger.error(f"Database test error: {e}")
        return jsonify({
            "success": False,
            "error": f"Database test failed: {str(e)}"
        }), 500

# ============================================================================
# DASHBOARD ENDPOINTS
# ============================================================================

@app.route('/api/dashboard/stats', methods=['GET'])
def get_dashboard_stats():
    """Get dashboard statistics"""
    try:
        # Count devices from devices.yaml
        devices_count = 0
        if Path("devices.yaml").exists():
            with open("devices.yaml", 'r') as f:
                devices = yaml.safe_load(f)
                devices_count = len([k for k in devices.keys() if k != 'defaults'])
        
        # Count configuration files (all yaml files in configs directory)
        config_files_count = 0
        configs_dir = Path("configs")
        if configs_dir.exists():
            config_files_count = len(list(configs_dir.rglob("*.yaml")))
        
        # Count bridge domains (bridge domain configuration files)
        bridge_domains_count = 0
        pending_dir = Path("configs/pending")
        if pending_dir.exists():
            bridge_domains_count = len([f for f in pending_dir.glob("*.yaml") 
                                      if "bridge_domain" in f.name or "unified_bridge_domain" in f.name])
        
        # Count active deployments (files in deployed directory)
        active_deployments_count = 0
        deployed_dir = Path("configs/deployed")
        if deployed_dir.exists():
            active_deployments_count = len(list(deployed_dir.glob("*.yaml")))
        
        return jsonify({
            "totalDevices": devices_count,
            "activeDeployments": active_deployments_count,
            "bridgeDomains": bridge_domains_count,
            "configFiles": config_files_count
        })
        
    except Exception as e:
        logger.error(f"Dashboard stats error: {e}")
        return jsonify({"error": "Failed to get dashboard stats"}), 500

@app.route('/api/dashboard/recent-activity', methods=['GET'])
def get_recent_activity():
    """Get recent activity for dashboard"""
    try:
        activities = []
        
        # Get recent bridge domain configurations
        pending_dir = Path("configs/pending")
        if pending_dir.exists():
            for config_file in pending_dir.glob("*.yaml"):
                if "bridge_domain" in config_file.name or "unified_bridge_domain" in config_file.name:
                    # Get file modification time
                    mtime = datetime.fromtimestamp(config_file.stat().st_mtime)
                    time_diff = datetime.now() - mtime
                    
                    # Format time difference
                    if time_diff.total_seconds() < 60:
                        time_ago = "just now"
                    elif time_diff.total_seconds() < 3600:
                        minutes = int(time_diff.total_seconds() / 60)
                        time_ago = f"{minutes} minute{'s' if minutes != 1 else ''} ago"
                    elif time_diff.total_seconds() < 86400:
                        hours = int(time_diff.total_seconds() / 3600)
                        time_ago = f"{hours} hour{'s' if hours != 1 else ''} ago"
                    else:
                        days = int(time_diff.total_seconds() / 86400)
                        time_ago = f"{days} day{'s' if days != 1 else ''} ago"
                    
                    activities.append({
                        "action": "Bridge Domain Created",
                        "device": config_file.stem,
                        "time": time_ago,
                        "status": "success"
                    })
        
        # Get recent deployments
        deployed_dir = Path("configs/deployed")
        if deployed_dir.exists():
            for config_file in deployed_dir.glob("*.yaml"):
                mtime = datetime.fromtimestamp(config_file.stat().st_mtime)
                time_diff = datetime.now() - mtime
                
                if time_diff.total_seconds() < 60:
                    time_ago = "just now"
                elif time_diff.total_seconds() < 3600:
                    minutes = int(time_diff.total_seconds() / 60)
                    time_ago = f"{minutes} minute{'s' if minutes != 1 else ''} ago"
                elif time_diff.total_seconds() < 86400:
                    hours = int(time_diff.total_seconds() / 3600)
                    time_ago = f"{hours} hour{'s' if hours != 1 else ''} ago"
                else:
                    days = int(time_diff.total_seconds() / 86400)
                    time_ago = f"{days} day{'s' if days != 1 else ''} ago"
                
                activities.append({
                    "action": "Configuration Deployed",
                    "device": config_file.stem,
                    "time": time_ago,
                    "status": "success"
                })
        
        # Sort by time (most recent first) and limit to 10 activities
        activities.sort(key=lambda x: x.get('time', ''), reverse=True)
        activities = activities[:10]
        
        # If no real activities, add some placeholder ones
        if not activities:
            activities = [
                {
                    "action": "System Ready",
                    "device": "Lab Automation Framework",
                    "time": "just now",
                    "status": "success"
                }
            ]
        
        return jsonify(activities)
        
    except Exception as e:
        logger.error(f"Recent activity error: {e}")
        return jsonify({"error": "Failed to get recent activity"}), 500

# ============================================================================
# BRIDGE DOMAIN BUILDER ENDPOINTS
# ============================================================================

@app.route('/api/builder/devices', methods=['GET'])
def get_devices():
    """Get list of available devices"""
    try:
        if not Path("devices.yaml").exists():
            return jsonify({"error": "devices.yaml not found"}), 404
        
        with open("devices.yaml", 'r') as f:
            devices = yaml.safe_load(f)
        
        # Filter out defaults and format for frontend
        device_list = []
        for device_name, device_info in devices.items():
            if device_name != 'defaults':
                device_type = device_info.get('device_type', 'unknown')
                device_list.append({
                    "name": device_name,
                    "type": device_type,
                    "mgmt_ip": device_info.get('mgmt_ip', ''),
                    "location": device_info.get('location', ''),
                    "status": device_info.get('status', 'unknown')
                })
        
        return jsonify(device_list)
        
    except Exception as e:
        logger.error(f"Get devices error: {e}")
        return jsonify({"error": "Failed to get devices"}), 500

@app.route('/api/builder/interfaces/<device>', methods=['GET'])
def get_interfaces(device):
    """Get available interfaces for a device"""
    try:
        # Generate interfaces like in CLI (ge100-0/0/1 through ge100-0/0/48)
        interfaces = []
        for i in range(1, 49):
            interfaces.append(f"ge100-0/0/{i}")
        
        # Add bundle interfaces
        bundle_interfaces = [
            "bundle-60000", "bundle-60001", "bundle-60002", "bundle-60003",
            "bundle-60004", "bundle-60005", "bundle-60006", "bundle-60007"
        ]
        interfaces.extend(bundle_interfaces)
        
        return jsonify(interfaces)
        
    except Exception as e:
        logger.error(f"Get interfaces error: {e}")
        return jsonify({"error": "Failed to get interfaces"}), 500

@app.route('/api/builder/validate', methods=['POST'])
def validate_builder_configuration():
    """Validate bridge domain configuration"""
    try:
        data = request.get_json()
        
        # Basic validation
        required_fields = ['username', 'vlanId', 'sourceDevice', 'sourceInterface', 'destinations']
        for field in required_fields:
            if field not in data:
                return jsonify({"valid": False, "errors": [f"Missing required field: {field}"]})
        
        # Additional validation logic here
        errors = []
        
        if not data['username']:
            errors.append("Username is required")
        
        if not data['vlanId'] or not data['vlanId'].isdigit():
            errors.append("Valid VLAN ID is required")
        
        if not data['sourceDevice']:
            errors.append("Source device is required")
        
        if not data['sourceInterface']:
            errors.append("Source interface is required")
        
        if not data['destinations'] or len(data['destinations']) == 0:
            errors.append("At least one destination is required")
        
        return jsonify({
            "valid": len(errors) == 0,
            "errors": errors
        })
        
    except Exception as e:
        logger.error(f"Validation error: {e}")
        return jsonify({"valid": False, "errors": ["Internal validation error"]}), 500

@app.route('/api/builder/generate', methods=['POST'])
def generate_builder_configuration():
    """Generate bridge domain configuration"""
    try:
        data = request.get_json()
        logger.info(f"Received configuration request: {data}")
        
        # Extract configuration data
        username = data.get('username', '')
        vlan_id = data.get('vlanId', '')
        source_device = data.get('sourceDevice', '')
        source_interface = data.get('sourceInterface', '')
        destinations = data.get('destinations', [])
        
        # Validate required fields
        if not username:
            return jsonify({"success": False, "error": "Username is required"}), 400
        if not vlan_id:
            return jsonify({"success": False, "error": "VLAN ID is required"}), 400
        if not source_device:
            return jsonify({"success": False, "error": "Source device is required"}), 400
        if not source_interface:
            return jsonify({"success": False, "error": "Source interface is required"}), 400
        if not destinations or len(destinations) == 0:
            return jsonify({"success": False, "error": "At least one destination is required"}), 400
        
        # Generate service name
        service_name = f"g_{username}_v{vlan_id}"
        logger.info(f"Generated service name: {service_name}")
        
        # Convert destinations to the format expected by unified builder
        dest_list = []
        for dest in destinations:
            dest_list.append({
                'device': dest['device'],
                'port': dest['interfaceName']
            })
        
        logger.info(f"Converted destinations: {dest_list}")
        
        # Check if devices.yaml exists and has data
        if not Path("devices.yaml").exists():
            return jsonify({"success": False, "error": "devices.yaml not found. Please populate devices from inventory first."}), 500
        
        with open("devices.yaml", 'r') as f:
            devices_data = yaml.safe_load(f)
        
        if not devices_data or 'defaults' not in devices_data:
            return jsonify({"success": False, "error": "devices.yaml is empty or invalid. Please populate devices from inventory first."}), 500
        
        # Check if source device exists in devices.yaml
        if source_device not in devices_data:
            return jsonify({"success": False, "error": f"Source device '{source_device}' not found in devices.yaml"}), 400
        
        # Check if destination devices exist in devices.yaml
        missing_devices = []
        for dest in dest_list:
            if dest['device'] not in devices_data:
                missing_devices.append(dest['device'])
        
        if missing_devices:
            return jsonify({"success": False, "error": f"Destination devices not found in devices.yaml: {', '.join(missing_devices)}"}), 400
        
        # Check topology data for spine connections
        topology_file = Path("topology/enhanced_topology.json")
        if topology_file.exists():
            with open(topology_file, 'r') as f:
                topology_data = json.load(f)
            
            devices = topology_data.get('devices', {})
            source_device_info = devices.get(source_device, {})
            connected_spines = source_device_info.get('connected_spines', [])
            
            if not connected_spines:
                # Check if there are any connections in the connections array
                connections = source_device_info.get('connections', [])
                spine_connections = [conn for conn in connections if 'DNAAS-SPINE' in conn.get('target_device', '')]
                
                if spine_connections:
                    spine_devices = list(set([conn['target_device'] for conn in spine_connections]))
                    return jsonify({
                        "success": False, 
                        "error": f"Source device '{source_device}' has spine connections but they are not properly formatted in topology data",
                        "details": f"Found spine connections to: {', '.join(spine_devices)}. The topology data needs to be updated to include these in the 'connected_spines' array."
                    }), 500
                else:
                    return jsonify({
                        "success": False, 
                        "error": f"Source device '{source_device}' has no spine connections in topology data",
                        "details": "This device cannot be used as a source for bridge domain configuration because it has no spine connections."
                    }), 500
        
        # Use the unified builder to generate configuration
        try:
            logger.info(f"Calling unified builder with: service_name={service_name}, vlan_id={vlan_id}, source_device={source_device}, source_interface={source_interface}, destinations={dest_list}")
            
            result = builder.build_bridge_domain_config(
                service_name=service_name,
                vlan_id=int(vlan_id),
                source_device=source_device,
                source_interface=source_interface,
                destinations=dest_list
            )
            
            # Handle both old format (dict) and new format (tuple with metadata)
            if isinstance(result, tuple):
                config_data, metadata = result
                logger.info(f"Unified builder returned config_data and metadata separately")
            else:
                config_data = result
                metadata = None
                logger.info(f"Unified builder returned config_data only (legacy format)")
            
            logger.info(f"Unified builder returned: {config_data}")
            
        except Exception as e:
            logger.error(f"Unified builder error: {e}")
            import traceback
            full_traceback = traceback.format_exc()
            logger.error(f"Full traceback: {full_traceback}")
            return jsonify({
                "success": False, 
                "error": f"Configuration generation failed: {str(e)}",
                "details": full_traceback
            }), 500
        
        if config_data:
            # Save configuration to database only (no file system)
            logger.info("=" * 50)
            logger.info("DATABASE SAVE DEBUG START")
            logger.info("=" * 50)
            
            # Get current count
            current_count = db_manager.get_configuration_count()
            logger.info(f"Current configurations in database: {current_count}")
            
            # Save configuration to database only
            save_success = db_manager.save_configuration(
                service_name=service_name,
                vlan_id=int(vlan_id),
                config_data=config_data,
                file_path=None,  # No file path needed
                config_metadata=metadata  # Pass metadata separately
            )
            
            if save_success:
                logger.info("‚úÖ Database save successful")
                
                # Verify the save
                if db_manager.verify_save(service_name):
                    logger.info("‚úÖ Database save verified")
                else:
                    logger.error("‚ùå Database save verification failed")
            else:
                logger.error("‚ùå Database save failed")
            
            # Get new count
            new_count = db_manager.get_configuration_count()
            logger.info(f"New configurations count: {new_count}")
            
            logger.info("=" * 50)
            logger.info("DATABASE SAVE DEBUG END")
            logger.info("=" * 50)
                
            return jsonify({
                "success": True,
                "config": config_data,
                "serviceName": service_name,
                "message": "Configuration saved to database successfully"
            })
        else:
            logger.error("Unified builder returned None/empty config")
            return jsonify({
                "success": False, 
                "error": "Failed to generate configuration - builder returned empty result",
                "details": "The unified builder did not generate any configuration. This might be due to topology issues or missing device connections."
            }), 500
        
    except Exception as e:
        logger.error(f"Generate configuration error: {e}")
        import traceback
        full_traceback = traceback.format_exc()
        logger.error(f"Full traceback: {full_traceback}")
        return jsonify({
            "success": False, 
            "error": f"Configuration generation failed: {str(e)}",
            "details": full_traceback
        }), 500

# ============================================================================
# BRIDGE DOMAIN DISCOVERY & VISUALIZATION ENDPOINTS
# ============================================================================

@app.route('/api/bridge-domains/discover', methods=['POST'])
def discover_bridge_domains():
    """Discover existing bridge domains across the network"""
    try:
        from config_engine.bridge_domain_discovery import BridgeDomainDiscovery
        
        discovery = BridgeDomainDiscovery()
        result = discovery.run_discovery()
        
        if result:
            return jsonify({
                "success": True,
                "message": "Bridge domain discovery completed successfully",
                "discovered_count": len(result.get('bridge_domains', {})),
                "mapping_file": str(discovery.output_dir / f"bridge_domain_mapping_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
            })
        else:
            return jsonify({
                "success": False,
                "error": "Bridge domain discovery failed"
            }), 500
            
    except Exception as e:
        logger.error(f"Bridge domain discovery error: {e}")
        return jsonify({
            "success": False,
            "error": f"Bridge domain discovery failed: {str(e)}"
        }), 500

@app.route('/api/bridge-domains/list', methods=['GET'])
def list_bridge_domains():
    """Get list of discovered bridge domains"""
    try:
        from config_engine.bridge_domain_visualization import BridgeDomainVisualization
        
        visualization = BridgeDomainVisualization()
        mapping = visualization.load_latest_mapping()
        
        if not mapping:
            return jsonify({
                "success": False,
                "error": "No bridge domain mapping found. Please run discovery first."
            }), 404
        
        bridge_domains = mapping.get('bridge_domains', {})
        bridge_domain_list = []
        
        for name, data in bridge_domains.items():
            topology_analysis = data.get('topology_analysis', {})
            bridge_domain_list.append({
                "name": name,
                "vlan": data.get('detected_vlan', 'unknown'),
                "username": data.get('detected_username', 'unknown'),
                "confidence": data.get('confidence', 0),
                "topology_type": data.get('topology_type', 'unknown'),
                "total_devices": len(data.get('devices', {})),
                "total_interfaces": topology_analysis.get('total_interfaces', 0),
                "access_interfaces": topology_analysis.get('access_interfaces', 0),
                "path_complexity": topology_analysis.get('path_complexity', 'unknown'),
                "detection_method": data.get('detection_method', 'unknown')
            })
        
        return jsonify({
            "success": True,
            "bridge_domains": bridge_domain_list,
            "total_count": len(bridge_domain_list),
            "summary": mapping.get('topology_summary', {})
        })
        
    except Exception as e:
        logger.error(f"List bridge domains error: {e}")
        return jsonify({
            "success": False,
            "error": f"Failed to list bridge domains: {str(e)}"
        }), 500

@app.route('/api/bridge-domains/<bridge_domain_name>/details', methods=['GET'])
def get_bridge_domain_details(bridge_domain_name):
    """Get detailed information about a specific bridge domain"""
    try:
        from config_engine.bridge_domain_visualization import BridgeDomainVisualization
        
        visualization = BridgeDomainVisualization()
        mapping = visualization.load_latest_mapping()
        
        if not mapping:
            return jsonify({
                "success": False,
                "error": "No bridge domain mapping found. Please run discovery first."
            }), 404
        
        bridge_domains = mapping.get('bridge_domains', {})
        bridge_domain_data = bridge_domains.get(bridge_domain_name)
        
        if not bridge_domain_data:
            return jsonify({
                "success": False,
                "error": f"Bridge domain '{bridge_domain_name}' not found"
            }), 404
        
        return jsonify({
            "success": True,
            "bridge_domain": bridge_domain_data
        })
        
    except Exception as e:
        logger.error(f"Get bridge domain details error: {e}")
        return jsonify({
            "success": False,
            "error": f"Failed to get bridge domain details: {str(e)}"
        }), 500

@app.route('/api/bridge-domains/<bridge_domain_name>/visualize', methods=['GET'])
def visualize_bridge_domain(bridge_domain_name):
    """Generate visualization for a specific bridge domain"""
    try:
        from config_engine.bridge_domain_visualization import BridgeDomainVisualization
        
        visualization = BridgeDomainVisualization()
        mapping = visualization.load_latest_mapping()
        
        if not mapping:
            return jsonify({
                "success": False,
                "error": "No bridge domain mapping found. Please run discovery first."
            }), 404
        
        # Generate visualization
        viz_result = visualization.visualize_bridge_domain_topology(bridge_domain_name, mapping)
        
        if viz_result.startswith("‚ùå"):
            return jsonify({
                "success": False,
                "error": viz_result
            }), 404
        
        # Generate details
        bridge_domain_data = mapping.get('bridge_domains', {}).get(bridge_domain_name)
        if bridge_domain_data:
            details = visualization.generate_bridge_domain_details(bridge_domain_data)
        else:
            details = "Details not available"
        
        return jsonify({
            "success": True,
            "visualization": viz_result,
            "details": details,
            "bridge_domain_name": bridge_domain_name
        })
        
    except Exception as e:
        logger.error(f"Visualize bridge domain error: {e}")
        return jsonify({
            "success": False,
            "error": f"Failed to visualize bridge domain: {str(e)}"
        }), 500

@app.route('/api/bridge-domains/search', methods=['GET'])
def search_bridge_domains():
    """Search bridge domains by name, VLAN, or username"""
    try:
        query = request.args.get('q', '').lower()
        if not query:
            return jsonify({
                "success": False,
                "error": "Search query is required"
            }), 400
        
        from config_engine.bridge_domain_visualization import BridgeDomainVisualization
        
        visualization = BridgeDomainVisualization()
        mapping = visualization.load_latest_mapping()
        
        if not mapping:
            return jsonify({
                "success": False,
                "error": "No bridge domain mapping found. Please run discovery first."
            }), 404
        
        bridge_domains = mapping.get('bridge_domains', {})
        results = []
        
        for name, data in bridge_domains.items():
            # Search in name, VLAN, and username
            if (query in name.lower() or 
                query in str(data.get('detected_vlan', '')).lower() or
                query in str(data.get('detected_username', '')).lower()):
                
                topology_analysis = data.get('topology_analysis', {})
                results.append({
                    "name": name,
                    "vlan": data.get('detected_vlan', 'unknown'),
                    "username": data.get('detected_username', 'unknown'),
                    "confidence": data.get('confidence', 0),
                    "topology_type": data.get('topology_type', 'unknown'),
                    "total_devices": len(data.get('devices', {})),
                    "total_interfaces": topology_analysis.get('total_interfaces', 0),
                    "access_interfaces": topology_analysis.get('access_interfaces', 0),
                    "path_complexity": topology_analysis.get('path_complexity', 'unknown'),
                    "detection_method": data.get('detection_method', 'unknown')
                })
        
        return jsonify({
            "success": True,
            "results": results,
            "total_count": len(results),
            "query": query
        })
        
    except Exception as e:
        logger.error(f"Search bridge domains error: {e}")
        return jsonify({
            "success": False,
            "error": f"Failed to search bridge domains: {str(e)}"
        }), 500

# Phase 1 Enhanced Bridge Domain Builder Endpoint
@app.route('/api/bridge-domains/enhanced-builder', methods=['POST'])
@token_required
def enhanced_bridge_domain_builder(current_user):
    """Enhanced bridge domain builder with Phase 1 validation and data structures"""
    try:
        logger.info(f"=== ENHANCED BRIDGE DOMAIN BUILDER DEBUG ===")
        logger.info(f"User: {current_user.username} (ID: {current_user.id})")
        
        data = request.get_json()
        service_name = data.get('service_name')
        vlan_id = data.get('vlan_id')
        source_device = data.get('source_device')
        source_interface = data.get('source_interface')
        destinations = data.get('destinations', [])
        
        # Validate required fields
        if not all([service_name, vlan_id, source_device, source_interface]):
            return jsonify({
                "success": False,
                "error": "service_name, vlan_id, source_device, and source_interface are required"
            }), 400
        
        if not destinations:
            return jsonify({
                "success": False,
                "error": "At least one destination is required"
            }), 400
        
        # Check if Enhanced Database is available
        if not enhanced_db_manager:
            return jsonify({
                "success": False,
                "error": "Enhanced Database not available",
                "enhanced_database_available": False
            }), 503
        
        logger.info(f"Building enhanced bridge domain: {service_name} (VLAN: {vlan_id})")
        logger.info(f"Source: {source_device}:{source_interface}")
        logger.info(f"Destinations: {destinations}")
        
        # Phase 1 validation
        try:
            from config_engine.phase1_integration import Phase1CLIWrapper
            
            cli_wrapper = Phase1CLIWrapper()
            validation_report = cli_wrapper.get_validation_report(
                service_name, vlan_id, source_device, source_interface, destinations
            )
            
            if not validation_report.get('passed'):
                return jsonify({
                    "success": False,
                    "error": "Phase 1 validation failed",
                    "validation_errors": validation_report.get('errors', []),
                    "validation_warnings": validation_report.get('warnings', [])
                }), 400
            
            logger.info("‚úÖ Phase 1 validation passed")
            
        except Exception as e:
            logger.warning(f"Phase 1 validation failed, continuing with legacy builder: {e}")
            # Continue with legacy builder if Phase 1 validation fails
        
        # Build configuration using existing builder
        try:
            from config_engine.unified_bridge_domain_builder import UnifiedBridgeDomainBuilder
            
            builder = UnifiedBridgeDomainBuilder()
            configs = builder.build_bridge_domain_config(
                service_name, vlan_id, source_device, source_interface, destinations
            )
            
            if not configs:
                return jsonify({
                    "success": False,
                    "error": "Failed to build bridge domain configuration"
                }), 500
            
            logger.info("‚úÖ Bridge domain configuration built successfully")
            
            # Save to Phase 1 database
            try:
                from config_engine.phase1_data_structures import create_p2mp_topology
                
                topology_data = create_p2mp_topology(
                    bridge_domain_name=service_name,
                    service_name=service_name,
                    vlan_id=vlan_id,
                    source_device=source_device,
                    source_interface=source_interface,
                    destinations=destinations
                )
                
                topology_id = enhanced_db_manager.save_topology_data(topology_data)
                
                if topology_id:
                    logger.info(f"üíæ Configuration saved to Phase 1 database (ID: {topology_id})")
                else:
                    logger.warning("‚ö†Ô∏è Failed to save to Phase 1 database")
                    
            except Exception as e:
                logger.warning(f"Phase 1 database save failed: {e}")
            
            # Create audit log
            create_audit_log(current_user.id, 'create', 'enhanced_bridge_domain', None, {
                'service_name': service_name,
                'vlan_id': vlan_id,
                'source_device': source_device,
                'source_interface': source_interface,
                'destinations_count': len(destinations),
                'phase1_integration': True,
                'topology_id': topology_id if 'topology_id' in locals() else None
            })
            
            # Return enhanced response
            device_count = len([k for k in configs.keys() if k != '_metadata'])
            
            return jsonify({
                "success": True,
                "message": f"Enhanced bridge domain '{service_name}' built successfully",
                "configuration": {
                    "service_name": service_name,
                    "vlan_id": vlan_id,
                    "devices_configured": device_count,
                    "topology_type": "P2MP" if len(destinations) > 1 else "P2P",
                    "phase1_integration": True,
                    "topology_id": topology_id if 'topology_id' in locals() else None
                },
                "enhanced_features": {
                    "validation": True,
                    "data_structure_consistency": True,
                    "advanced_topology_insights": True,
                    "export_import_capability": True
                }
            })
            
        except Exception as e:
            logger.error(f"Bridge domain builder failed: {e}")
            return jsonify({
                "success": False,
                "error": f"Bridge domain builder failed: {str(e)}"
            }), 500
        
    except Exception as e:
        logger.error(f"Enhanced bridge domain builder error: {e}")
        return jsonify({
            "success": False,
            "error": f"Enhanced bridge domain builder failed: {str(e)}"
        }), 500

# ============================================================================
# FILE MANAGEMENT ENDPOINTS
# ============================================================================

@app.route('/api/files/list', methods=['GET'])
def list_files():
    """List files in the project directory"""
    try:
        path = request.args.get('path', '.')
        base_path = Path(path)
        
        if not base_path.exists():
            return jsonify({"error": "Path not found"}), 404
        
        files = []
        for item in base_path.iterdir():
            if item.name.startswith('.'):
                continue  # Skip hidden files
            
            file_info = {
                "name": item.name,
                "type": "directory" if item.is_dir() else "file",
                "size": item.stat().st_size if item.is_file() else 0,
                "modified": datetime.fromtimestamp(item.stat().st_mtime).isoformat()
            }
            files.append(file_info)
        
        # Sort: directories first, then files
        files.sort(key=lambda x: (x['type'] == 'file', x['name'].lower()))
        
        return jsonify({
            "path": str(base_path),
            "files": files
        })
        
    except Exception as e:
        logger.error(f"List files error: {e}")
        return jsonify({"error": "Failed to list files"}), 500

@app.route('/api/files/download/<path:filepath>', methods=['GET'])
def download_file(filepath):
    """Download a file"""
    try:
        file_path = Path(filepath)
        if not file_path.exists():
            return jsonify({"error": "File not found"}), 404
        
        return send_file(file_path, as_attachment=True)
        
    except Exception as e:
        logger.error(f"Download file error: {e}")
        return jsonify({"error": "Failed to download file"}), 500

@app.route('/api/files/content/<path:filepath>', methods=['GET'])
def get_file_content(filepath):
    """Get file content as text"""
    try:
        file_path = Path(filepath)
        if not file_path.exists():
            return jsonify({"error": "File not found"}), 404
        
        if not file_path.is_file():
            return jsonify({"error": "Not a file"}), 400
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        return jsonify({
            "content": content,
            "filename": file_path.name,
            "size": file_path.stat().st_size,
            "modified": datetime.fromtimestamp(file_path.stat().st_mtime).isoformat()
        })
        
    except Exception as e:
        logger.error(f"Get file content error: {e}")
        return jsonify({"error": "Failed to read file content"}), 500

@app.route('/api/files/delete/<path:filepath>', methods=['DELETE'])
def delete_file(filepath):
    """Delete a file"""
    try:
        file_path = Path(filepath)
        if not file_path.exists():
            return jsonify({"error": "File not found"}), 404
        
        # Only allow deletion of files in configs directories for safety
        if not (str(file_path).startswith('configs/') or str(file_path).startswith('./configs/')):
            return jsonify({"error": "Can only delete files in configs directory"}), 403
        
        file_path.unlink()
        
        return jsonify({
            "success": True,
            "message": f"File {file_path.name} deleted successfully"
        })
        
    except Exception as e:
        logger.error(f"Delete file error: {e}")
        return jsonify({"error": "Failed to delete file"}), 500

@app.route('/api/files/save-config', methods=['POST'])
def save_file_configuration():
    """Save generated configuration to pending directory"""
    try:
        data = request.get_json()
        config_content = data.get('content')
        filename = data.get('filename')
        
        if not config_content:
            return jsonify({"error": "Configuration content is required"}), 400
        
        if not filename:
            return jsonify({"error": "Filename is required"}), 400
        
        # Ensure configs/pending directory exists
        pending_dir = Path("configs/pending")
        pending_dir.mkdir(parents=True, exist_ok=True)
        
        # Save the configuration
        config_path = pending_dir / filename
        with open(config_path, 'w', encoding='utf-8') as f:
            f.write(config_content)
        
        return jsonify({
            "success": True,
            "message": f"Configuration saved as {filename}",
            "path": str(config_path)
        })
        
    except Exception as e:
        logger.error(f"Save configuration error: {e}")
        return jsonify({"error": "Failed to save configuration"}), 500

# ============================================================================
# DEPLOYMENT MANAGEMENT ENDPOINTS (LEGACY - REMOVED)
# ============================================================================
# Note: These endpoints have been replaced by the unified configuration endpoints
# below. The old deployment endpoints caused function name conflicts.

@app.route('/api/deployments/list', methods=['GET'])
def list_deployments():
    """List pending and deployed configurations"""
    try:
        deployments = []
        
        # Check configs/pending directory
        pending_dir = Path("configs/pending")
        if pending_dir.exists():
            for config_file in pending_dir.glob("*.yaml"):
                deployments.append({
                    "name": config_file.stem,
                    "status": "pending",
                    "filename": config_file.name,
                    "modified": datetime.fromtimestamp(config_file.stat().st_mtime).isoformat()
                })
        
        # Check configs/deployed directory
        deployed_dir = Path("configs/deployed")
        if deployed_dir.exists():
            for config_file in deployed_dir.glob("*.yaml"):
                deployments.append({
                    "name": config_file.stem,
                    "status": "deployed",
                    "filename": config_file.name,
                    "modified": datetime.fromtimestamp(config_file.stat().st_mtime).isoformat()
                })
        
        return jsonify(deployments)
        
    except Exception as e:
        logger.error(f"List deployments error: {e}")
        return jsonify({"error": "Failed to list deployments"}), 500

@app.route('/api/deployments/start', methods=['POST'])
def start_deployment():
    """Start a configuration deployment"""
    try:
        data = request.get_json()
        config_filename = data.get('filename')
        
        if not config_filename:
            return jsonify({"error": "Filename is required"}), 400
        
        # Generate deployment ID
        deployment_id = f"deployment_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # Start deployment in background (placeholder)
        # In production, use Celery or similar for background tasks
        
        return jsonify({
            "success": True,
            "deploymentId": deployment_id,
            "message": "Deployment started"
        })
        
    except Exception as e:
        logger.error(f"Start deployment error: {e}")
        return jsonify({"error": "Failed to start deployment"}), 500

@app.route('/api/deployments/configurations', methods=['GET'])
@token_required
def get_user_configurations(current_user):
    """Get user's configurations for deployment management"""
    try:
        # Get configurations for the current user
        configs = Configuration.query.filter_by(user_id=current_user.id).all()
        
        configurations = []
        for config in configs:
            config_dict = config.to_dict()
            # Parse config_data if it's JSON
            if config.config_data:
                try:
                    import json
                    config_dict['config_data'] = json.dumps(json.loads(config.config_data), indent=2)
                except:
                    config_dict['config_data'] = config.config_data
            
            configurations.append(config_dict)
        
        return jsonify({
            "success": True,
            "configurations": configurations
        })
        
    except Exception as e:
        logger.error(f"Get configurations error: {e}")
        return jsonify({
            "success": False,
            "error": "Failed to get configurations"
        }), 500

@app.route('/api/deployments/test', methods=['GET'])
def test_deployments():
    """Test route for deployments"""
    return jsonify({
        "success": True,
        "message": "Deployments test route works"
    })

@app.route('/api/deployments/<deployment_id>/status', methods=['GET'])
@token_required
def get_deployment_status(current_user, deployment_id):
    """Get current deployment or removal status"""
    try:
        # Use the global deployment manager instance
        status = deployment_manager.get_deployment_status(deployment_id)
        
        if status:
            return jsonify({
                'success': True,
                'deployment_id': deployment_id,
                'status': status['status'],
                'progress': status['progress'],
                'stage': status['stage'],
                'logs': status['logs'][-20:],  # Last 20 log entries
                'errors': status.get('errors', []),
                'device_results': status.get('device_results', {}),
                'start_time': status['start_time'],
                'end_time': status.get('end_time'),
                'timestamp': status['timestamp']
            })
        else:
            return jsonify({
                'success': False,
                'error': 'Deployment/removal not found'
            }), 404
            
    except Exception as e:
        logger.error(f"Error getting deployment status: {e}")
        return jsonify({
            'success': False,
            'error': f'Failed to get status: {str(e)}'
        }), 500

# ============================================================================
# WEBSOCKET EVENTS
# ============================================================================

@socketio.on('connect')
def handle_connect():
    """Handle client connection"""
    logger.info(f"Client connected: {request.sid}")
    emit('connected', {'data': 'Connected to Lab Automation API'})

@socketio.on('disconnect')
def handle_disconnect():
    """Handle client disconnection"""
    logger.info(f"Client disconnected: {request.sid}")

@socketio.on('subscribe')
def handle_subscription(data):
    """Handle deployment subscription"""
    deployment_id = data.get('deploymentId')
    if deployment_id:
        join_room(deployment_id)
        logger.info(f"Client {request.sid} subscribed to deployment {deployment_id}")
        
        # Send current status immediately
        deployment_info = deployment_manager.get_deployment_status(deployment_id)
        if deployment_info:
            emit('deployment_update', {
                'deployment_id': deployment_id,
                'status': deployment_info['status'],
                'progress': deployment_info['progress'],
                'stage': deployment_info['stage'],
                'logs': deployment_info['logs'][-10:],
                'errors': deployment_info.get('errors', []),
                'device_results': deployment_info.get('device_results', {}),
                'timestamp': datetime.utcnow().isoformat()
            })

@socketio.on('unsubscribe')
def handle_unsubscription(data):
    """Handle deployment unsubscription"""
    deployment_id = data.get('deploymentId')
    if deployment_id:
        leave_room(deployment_id)
        logger.info(f"Client {request.sid} unsubscribed from deployment {deployment_id}")

def emit_deployment_progress(deployment_id, progress_data):
    """Emit deployment progress to subscribed clients"""
    socketio.emit('deployment_update', progress_data, room=deployment_id)

# ============================================================================
# HEALTH CHECK
# ============================================================================

@app.route('/api/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    return jsonify({
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "version": VERSION
    })

@app.route('/api/database/health', methods=['GET'])
def database_health_check():
    """Check database health and test save operations"""
    try:
        # Perform database health check
        health_result = db_manager.health_check()
        
        return jsonify({
            "success": True,
            **health_result
        })
        
    except Exception as e:
        logger.error(f"Database health check failed: {e}")
        return jsonify({
            "success": False,
            "database_healthy": False,
            "error": str(e)
        }), 500

# ============================================================================
# UNIFIED CONFIGURATION MANAGEMENT ENDPOINTS
# ============================================================================

@app.route('/api/configurations', methods=['GET'])
@token_required
def get_configurations(current_user):
    """Get all configurations and imported bridge domains for the current user"""
    try:
        logger.info(f"=== GET CONFIGURATIONS DEBUG ===")
        logger.info(f"User: {current_user.username} (ID: {current_user.id})")
        
        # Optional filters
        source_filter = request.args.get('source')  # reverse_engineered | manual
        bridge_domain_filter = request.args.get('bridgeDomain')

        # Get configurations from database
        configurations_query = Configuration.query.filter_by(user_id=current_user.id)
        if source_filter == 'reverse_engineered':
            configurations_query = configurations_query.filter(Configuration.is_reverse_engineered == True)
        elif source_filter == 'manual':
            configurations_query = configurations_query.filter((Configuration.is_reverse_engineered == False) | (Configuration.is_reverse_engineered.is_(None)))
        if bridge_domain_filter:
            configurations_query = configurations_query.filter(Configuration.service_name.contains(bridge_domain_filter))
        configurations = configurations_query.order_by(Configuration.created_at.desc()).all()
        logger.info(f"Found {len(configurations)} configurations")
        
        # Get imported bridge domains
        personal_bd_query = PersonalBridgeDomain.query.filter_by(user_id=current_user.id)
        if bridge_domain_filter:
            personal_bd_query = personal_bd_query.filter(PersonalBridgeDomain.bridge_domain_name.contains(bridge_domain_filter))
        personal_bridge_domains = personal_bd_query.order_by(PersonalBridgeDomain.created_at.desc()).all()
        logger.info(f"Found {len(personal_bridge_domains)} personal bridge domains")
        
        config_list = []
        # Build quick lookup by bridge_domain_name for enrichment
        bd_by_name = {bd.bridge_domain_name: bd for bd in personal_bridge_domains}
        
        # Add actual configurations
        for config in configurations:
            logger.info(f"Adding configuration: {config.service_name}")
            linked_bd = bd_by_name.get(config.service_name)
            config_list.append({
                'id': config.id,
                'service_name': config.service_name,
                'vlan_id': config.vlan_id,
                'config_type': config.config_type,
                'status': config.status,
                'config_data': config.config_data,
                'source': config.config_source or ('reverse_engineered' if config.is_reverse_engineered else 'manual'),
                'config_source': config.config_source or ('reverse_engineered' if config.is_reverse_engineered else 'manual'),
                'builder_type': getattr(config, 'builder_type', None),
                'topology_type': getattr(config, 'topology_type', None),
                'derived_from_scan_id': getattr(config, 'derived_from_scan_id', None),
                'builder_input_available': bool(getattr(config, 'builder_input', None)),
                'original_bridge_domain_id': getattr(linked_bd, 'id', None),
                'imported_from_topology': getattr(linked_bd, 'imported_from_topology', None) if linked_bd else None,
                'created_at': config.created_at.isoformat() if config.created_at else None,
                'deployed_at': config.deployed_at.isoformat() if config.deployed_at else None,
                'deployed_by': config.deployed_by,
                'type': 'configuration'  # Mark as actual configuration
            })
        
        # Add imported bridge domains
        for bd in personal_bridge_domains:
            logger.info(f"Adding imported bridge domain: {bd.bridge_domain_name}")
            # Skip imported BD if it has been reverse engineered (to avoid duplicate visible entries)
            if getattr(bd, 'reverse_engineered_config_id', None):
                logger.info(f"Skipping imported BD {bd.bridge_domain_name} because it is linked to config {bd.reverse_engineered_config_id}")
                continue
            config_list.append({
                'id': f"bd_{bd.id}",  # Use prefix to distinguish from config IDs
                'service_name': bd.bridge_domain_name,
                'vlan_id': None,  # Will be extracted from bridge domain name or scan
                'config_type': 'bridge_domain',
                'status': 'imported',
                'config_data': None,  # Will be populated after scan
                'created_at': bd.created_at.isoformat() if bd.created_at else None,
                'deployed_at': None,
                'deployed_by': None,
                'type': 'imported_bridge_domain',  # Mark as imported bridge domain
                'topology_scanned': bd.topology_scanned,
                'last_scan_at': bd.last_scan_at.isoformat() if bd.last_scan_at else None,
                'imported_from_topology': bd.imported_from_topology
            })
        
        # Sort by creation date (newest first)
        config_list.sort(key=lambda x: x['created_at'] or '', reverse=True)
        logger.info(f"Total items in response: {len(config_list)}")
        logger.info(f"Configurations: {len([c for c in config_list if c['type'] == 'configuration'])}")
        logger.info(f"Imported bridge domains: {len([c for c in config_list if c['type'] == 'imported_bridge_domain'])}")
        logger.info("=== GET CONFIGURATIONS DEBUG END ===")
        
        return jsonify({
            "success": True,
            "configurations": config_list,
            "total": len(config_list),
            "configurations_count": len([c for c in config_list if c['type'] == 'configuration']),
            "imported_bridge_domains_count": len([c for c in config_list if c['type'] == 'imported_bridge_domain'])
        })
        
    except Exception as e:
        logger.error(f"Get configurations error: {e}")
        return jsonify({
            "success": False,
            "error": f"Failed to get configurations: {str(e)}"
        }), 500

# Enhanced Phase 1 configurations endpoint
@app.route('/api/configurations/enhanced', methods=['GET'])
@token_required
def get_enhanced_configurations(current_user):
    """Get enhanced configurations with Phase 1 data structures and validation"""
    try:
        logger.info(f"=== GET ENHANCED CONFIGURATIONS DEBUG ===")
        logger.info(f"User: {current_user.username} (ID: {current_user.id})")
        
        # Check if Enhanced Database is available
        if not enhanced_db_manager:
            return jsonify({
                "success": False,
                "error": "Enhanced Database not available",
                "enhanced_database_available": False
            }), 503
        
        # Get Enhanced Database topologies
        try:
            topologies = enhanced_db_manager.get_all_topologies(limit=1000)
            logger.info(f"Found {len(topologies)} Enhanced Database topologies")
        except Exception as e:
            logger.error(f"Failed to get Enhanced Database topologies: {e}")
            topologies = []
        
        # Get legacy configurations
        try:
            configurations = Configuration.query.filter_by(user_id=current_user.id).order_by(Configuration.created_at.desc()).all()
            logger.info(f"Found {len(configurations)} legacy configurations")
        except Exception as e:
            logger.error(f"Failed to get legacy configurations: {e}")
            configurations = []
        
        # Build enhanced response
        enhanced_list = []
        
        # Add Phase 1 topologies
        for topology in topologies:
            enhanced_list.append({
                'id': f"phase1_{getattr(topology, 'id', 'N/A')}",
                'service_name': getattr(topology, 'bridge_domain_name', 'N/A'),
                'vlan_id': getattr(topology, 'vlan_id', None),
                'config_type': 'phase1_topology',
                'status': 'enhanced',
                'phase1_data': {
                    'topology_type': getattr(topology, 'topology_type', 'N/A'),
                    'device_count': len(getattr(topology, 'devices', [])),
                    'interface_count': len(getattr(topology, 'interfaces', [])),
                    'path_count': len(getattr(topology, 'paths', [])),
                    'validation_status': 'validated' if hasattr(topology, 'validation_status') else 'unknown'
                },
                'created_at': getattr(topology, 'created_at', 'N/A'),
                'updated_at': getattr(topology, 'updated_at', 'N/A'),
                'type': 'phase1_topology',
                'enhanced_features': True
            })
        
        # Add legacy configurations with Phase 1 enrichment
        for config in configurations:
            enhanced_list.append({
                'id': config.id,
                'service_name': config.service_name,
                'vlan_id': config.vlan_id,
                'config_type': config.config_type,
                'status': config.status,
                'config_data': config.config_data,
                'source': config.config_source or ('reverse_engineered' if config.is_reverse_engineered else 'manual'),
                'created_at': config.created_at.isoformat() if config.created_at else None,
                'deployed_at': config.deployed_at.isoformat() if config.deployed_at else None,
                'deployed_by': config.deployed_by,
                'type': 'legacy_configuration',
                'enhanced_features': False,
                'phase1_migration_available': True
            })
        
        # Sort by creation date (newest first)
        enhanced_list.sort(key=lambda x: x.get('created_at', '') or '', reverse=True)
        
        logger.info(f"Total enhanced items: {len(enhanced_list)}")
        logger.info(f"Phase 1 topologies: {len([c for c in enhanced_list if c['type'] == 'phase1_topology'])}")
        logger.info(f"Legacy configurations: {len([c for c in enhanced_list if c['type'] == 'legacy_configuration'])}")
        logger.info("=== GET ENHANCED CONFIGURATIONS DEBUG END ===")
        
        return jsonify({
            "success": True,
            "enhanced_configurations": enhanced_list,
            "total": len(enhanced_list),
            "phase1_available": True,
            "enhanced_features": {
                "topology_validation": True,
                "data_structure_consistency": True,
                "advanced_search": True,
                "export_import": True,
                "legacy_migration": True
            }
        })
        
    except Exception as e:
        logger.error(f"Get enhanced configurations error: {e}")
        return jsonify({
            "success": False,
            "error": str(e),
            "phase1_available": phase1_db_manager is not None
        }), 500

@app.route('/api/test/metadata', methods=['GET'])
def test_metadata():
    """Test endpoint for metadata"""
    return jsonify({
        "success": True,
        "message": "Test metadata endpoint works"
    })

@app.route('/api/configurations/<int:config_id>/metadata', methods=['GET'])
@token_required
@user_ownership_required
def get_configuration_metadata(current_user, config_id):
    """Get metadata for a specific configuration"""
    try:
        # Get configuration from database
        config = Configuration.query.get(config_id)
        if not config:
            return jsonify({
                "success": False,
                "error": "Configuration not found"
            }), 404
        
        # Parse metadata if it exists
        metadata = None
        if config.config_metadata:
            try:
                metadata = json.loads(config.config_metadata)
            except json.JSONDecodeError:
                return jsonify({
                    "success": False,
                    "error": "Invalid metadata format"
                }), 500
        
        return jsonify({
            "success": True,
            "metadata": metadata,
            "service_name": config.service_name,
            "vlan_id": config.vlan_id
        })
        
    except Exception as e:
        logger.error(f"Error getting configuration metadata: {e}")
        return jsonify({
            "success": False,
            "error": f"Failed to get configuration metadata: {str(e)}"
        }), 500

@app.route('/api/configurations/<int:config_id>/preview-deployment', methods=['GET'])
@token_required
@user_ownership_required
def preview_deployment_commands(current_user, config_id):
    """Preview deployment commands for a configuration"""
    try:
        # Get configuration details
        config = Configuration.query.get(config_id)
        if not config:
            return jsonify({
                "success": False,
                "error": "Configuration not found"
            }), 404
        
        # Import SSH push manager for preview
        from config_engine.ssh_push_manager import SSHPushManager
        push_manager = SSHPushManager()
        
        # Get deployment preview
        success, errors, device_commands = push_manager.preview_cli_commands(config.service_name)
        
        if not success:
            return jsonify({
                "success": False,
                "error": f"Failed to generate deployment preview: {'; '.join(errors)}"
            }), 400
        
        # Format the preview for display
        preview_data = {
            "configuration": {
                "id": config.id,
                "service_name": config.service_name,
                "vlan_id": config.vlan_id,
                "status": config.status,
                "devices": [device for device in device_commands.keys() if device != '_metadata']
            },
            "deployment_commands": device_commands,
            "total_devices": len([device for device in device_commands.keys() if device != '_metadata']),
            "total_commands": sum(len(cmds) for cmds in device_commands.values())
        }
        
        return jsonify({
            "success": True,
            "preview": preview_data
        })
        
    except Exception as e:
        logger.error(f"Error previewing deployment commands: {e}")
        return jsonify({
            "success": False,
            "error": f"Failed to preview deployment commands: {str(e)}"
        }), 500

@app.route('/api/configurations/<int:config_id>', methods=['GET'])
@token_required
@user_ownership_required
def get_configuration_details(current_user, config_id):
    """Get detailed configuration information"""
    try:
        config = Configuration.query.get(config_id)
        if not config:
            return jsonify({
                "success": False,
                "error": "Configuration not found"
            }), 404
        
        # Parse configuration data
        import json
        config_data = json.loads(config.config_data) if config.config_data else {}
        
        return jsonify({
            "success": True,
            "configuration": {
                'id': config.id,
                'service_name': config.service_name,
                'vlan_id': config.vlan_id,
                'config_type': config.config_type,
                'status': config.status,
                'config_data': config_data,
                'created_at': config.created_at.isoformat() if config.created_at else None,
                'deployed_at': config.deployed_at.isoformat() if config.deployed_at else None,
                'deployed_by': config.deployed_by
            }
        })
        
    except Exception as e:
        logger.error(f"Get configuration details error: {e}")
        return jsonify({
            "success": False,
            "error": f"Failed to get configuration details: {str(e)}"
        }), 500

@app.route('/api/configurations/<int:config_id>/validate', methods=['POST'])
@token_required
@user_ownership_required
def validate_unified_configuration(current_user, config_id):
    """Validate a configuration"""
    try:
        config = Configuration.query.get(config_id)
        if not config:
            return jsonify({
                "success": False,
                "error": "Configuration not found"
            }), 404
        
        # Parse configuration data
        import json
        config_data = json.loads(config.config_data) if config.config_data else {}
        
        if not config_data:
            return jsonify({
                "success": False,
                "error": "Configuration data is empty"
            }), 400
        
        # Check that we have devices in the configuration
        devices = [device for device in config_data.keys() if device != '_metadata']
        if not devices:
            return jsonify({
                "success": False,
                "error": "No devices found in configuration"
            }), 400
        
        # Validate device connectivity
        validation_errors = []
        for device in devices:
            # Check if device exists in devices.yaml
            if not Path("devices.yaml").exists():
                validation_errors.append("devices.yaml not found")
                break
            
            with open("devices.yaml", 'r') as f:
                devices_data = yaml.safe_load(f)
            
            if device not in devices_data:
                validation_errors.append(f"Device '{device}' not found in devices.yaml")
        
        if validation_errors:
            return jsonify({
                "success": False,
                "error": "Configuration validation failed",
                "details": validation_errors
            }), 400
        
        return jsonify({
            "success": True,
            "message": f"Configuration validated successfully for {len(devices)} devices",
            "device_count": len(devices)
        })
        
    except Exception as e:
        logger.error(f"Validate configuration error: {e}")
        return jsonify({
            "success": False,
            "error": f"Validation failed: {str(e)}"
        }), 500

@app.route('/api/configurations/<int:config_id>/deploy', methods=['POST'])
@token_required
@user_ownership_required
def deploy_unified_configuration(current_user, config_id):
    """Deploy a configuration via SSH with real-time progress"""
    try:
        config = Configuration.query.get(config_id)
        if not config:
            return jsonify({
                "success": False,
                "error": "Configuration not found"
            }), 404
        
        # Generate deployment ID
        deployment_id = f"deploy_{config_id}_{int(datetime.now().timestamp())}"
        
        # Parse configuration data
        import json
        config_data = json.loads(config.config_data) if config.config_data else {}
        
        if not config_data:
            return jsonify({
                "success": False,
                "error": "Configuration data is empty"
            }), 400
        
        # Start deployment with real-time progress
        success = deployment_manager.start_deployment(
            deployment_id=deployment_id,
            config_id=config_id,
            config_data=config_data,
            user_id=current_user.id
        )
        
        if not success:
            return jsonify({
                "success": False,
                "error": "Failed to start deployment"
            }), 500
        
        # Create audit log for deployment start
        create_audit_log(current_user.id, 'deploy_start', 'configuration', config_id, {
            'service_name': config.service_name,
            'deployment_id': deployment_id
        })
        
        return jsonify({
            "success": True,
            "deploymentId": deployment_id,
            "message": "Deployment started with real-time progress monitoring"
        })
        
    except Exception as e:
        logger.error(f"Deploy configuration error: {e}")
        return jsonify({
            "success": False,
            "error": f"Deployment failed: {str(e)}"
        }), 500

@app.route('/api/configurations/<int:config_id>', methods=['DELETE'])
@token_required
@user_ownership_required
def delete_unified_configuration(current_user, config_id):
    """Delete a configuration"""
    try:
        config = Configuration.query.get(config_id)
        if not config:
            return jsonify({
                "success": False,
                "error": "Configuration not found"
            }), 404
        
        # Check if configuration is currently being deployed
        deployment_info = deployment_manager.get_deployment_status(f"deploy_{config_id}_*")
        if deployment_info and deployment_info.get('status') == 'running':
            return jsonify({
                "success": False,
                "error": "Cannot delete configuration while deployment is in progress"
            }), 400
        
        # Clear link from any PersonalBridgeDomain
        try:
            bd_link = PersonalBridgeDomain.query.filter_by(reverse_engineered_config_id=config_id).first()
            if bd_link:
                bd_link.reverse_engineered_config_id = None
        except Exception as e:
            logger.warning(f"Failed to clear PersonalBridgeDomain link for config {config_id}: {e}")
        
        # Delete the configuration
        db.session.delete(config)
        db.session.commit()
        
        # Create audit log
        create_audit_log(current_user.id, 'delete', 'configuration', config_id, {
            'service_name': config.service_name
        })
        
        return jsonify({
            "success": True,
            "message": f"Configuration '{config.service_name}' deleted successfully"
        })
        
    except Exception as e:
        logger.error(f"Delete configuration error: {e}")
        return jsonify({
            "success": False,
            "error": f"Failed to delete configuration: {str(e)}"
        }), 500

@app.route('/api/configurations/<int:config_id>/export', methods=['POST'])
@token_required
@user_ownership_required
def export_configuration(current_user, config_id):
    """Export configuration to file (optional feature)"""
    try:
        config = Configuration.query.get(config_id)
        if not config:
            return jsonify({
                "success": False,
                "error": "Configuration not found"
            }), 404
        
        # Parse configuration data
        import json
        config_data = json.loads(config.config_data) if config.config_data else {}
        
        # Create export directory
        export_dir = Path("configs/exports")
        export_dir.mkdir(parents=True, exist_ok=True)
        
        # Generate filename
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{config.service_name}_{timestamp}.yaml"
        file_path = export_dir / filename
        
        # Save to file
        with open(file_path, 'w') as f:
            yaml.dump(config_data, f, default_flow_style=False)
        
        return jsonify({
            "success": True,
            "message": f"Configuration exported to {filename}",
            "file_path": str(file_path)
        })
        
    except Exception as e:
        logger.error(f"Export configuration error: {e}")
        return jsonify({
            "success": False,
            "error": f"Failed to export configuration: {str(e)}"
        }), 500

# ============================================================================
# DEPLOYMENT ENDPOINTS
# ============================================================================

@app.route('/api/deployments/<int:config_id>/preview-deletion', methods=['GET'])
@token_required
@user_ownership_required
def preview_deletion_commands(current_user, config_id):
    """Preview deletion commands for a configuration"""
    try:
        # Get configuration details
        config = Configuration.query.get(config_id)
        if not config:
            return jsonify({
                "success": False,
                "error": "Configuration not found"
            }), 404
        
        # Import SSH push manager for preview
        from config_engine.ssh_push_manager import SSHPushManager
        push_manager = SSHPushManager()
        
        # Get deletion preview
        success, errors, device_commands = push_manager.preview_deletion_commands(config.service_name)
        
        if not success:
            return jsonify({
                "success": False,
                "error": f"Failed to generate deletion preview: {'; '.join(errors)}"
            }), 400
        
        # Format the preview for display
        preview_data = {
            "configuration": {
                "id": config.id,
                "service_name": config.service_name,
                "vlan_id": config.vlan_id,
                "status": config.status,
                "devices": [device for device in device_commands.keys() if device != '_metadata']
            },
            "deletion_commands": device_commands,
            "total_devices": len([device for device in device_commands.keys() if device != '_metadata']),
            "total_commands": sum(len(cmds) for cmds in device_commands.values())
        }
        
        return jsonify({
            "success": True,
            "preview": preview_data
        })
        
    except Exception as e:
        logger.error(f"Error previewing deletion commands: {e}")
        return jsonify({
            "success": False,
            "error": f"Failed to preview deletion commands: {str(e)}"
        }), 500

@app.route('/api/deployments/<int:config_id>/remove', methods=['POST'])
@token_required
@user_ownership_required
def remove_from_devices(current_user, config_id):
    """Remove a configuration from devices with progress tracking"""
    try:
        # Get configuration details
        config = Configuration.query.get(config_id)
        if not config:
            return jsonify({
                "success": False,
                "error": "Configuration not found"
            }), 404
        
        # Create a unique removal ID for tracking
        removal_id = f"remove_{config_id}_{int(time.time())}"
        
        # Start removal in background with progress tracking
        from deployment_manager import DeploymentManager
        deployment_manager = DeploymentManager(socketio)
        
        # Start the removal process
        success = deployment_manager.start_removal(
            removal_id, config_id, config.config_data, current_user.id
        )
        
        if success:
            return jsonify({
                'success': True, 
                'message': 'Configuration removal started',
                'removal_id': removal_id
            })
        else:
            return jsonify({'success': False, 'error': 'Failed to start removal'}), 500
        
    except Exception as e:
        logger.error(f"Error starting removal: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/deployments/<int:config_id>/restore', methods=['POST'])
@token_required
@user_ownership_required
def restore_configuration(current_user, config_id):
    """Restore a deleted configuration to pending status"""
    try:
        # Get configuration details
        config = Configuration.query.get(config_id)
        if not config:
            return jsonify({
                "success": False,
                "error": "Configuration not found"
            }), 404
        
        # Update configuration status to 'pending'
        config.status = 'pending'
        db.session.commit()
        
        # Create audit log
        create_audit_log(current_user.id, 'restore', 'configuration', config_id, {
            'service_name': config.service_name
        })
        
        return jsonify({
            "success": True,
            "message": f"Configuration '{config.service_name}' restored successfully"
        })
        
    except Exception as e:
        logger.error(f"Error restoring configuration: {e}")
        return jsonify({
            "success": False,
            "error": f"Failed to restore configuration: {str(e)}"
        }), 500

# ============================================================================
# ADMIN USER MANAGEMENT ENDPOINTS
# ============================================================================

@app.route('/api/admin/users', methods=['GET'])
@token_required
@admin_required
def get_users(current_user):
    """Get all users (admin only)"""
    try:
        users = User.query.all()
        users_data = []
        
        for user in users:
            user_data = user.to_dict()
            # Add additional info for admin view
            user_data['configurations_count'] = len(user.configurations)
            user_data['personal_bridge_domains_count'] = len(user.personal_bridge_domains)
            users_data.append(user_data)
        
        return jsonify({
            "success": True,
            "users": users_data
        })
        
    except Exception as e:
        logger.error(f"Error getting users: {e}")
        return jsonify({
            "success": False,
            "error": f"Failed to get users: {str(e)}"
        }), 500

@app.route('/api/admin/users', methods=['POST'])
@token_required
@admin_required
def create_user(current_user):
    """Create new user (admin only)"""
    try:
        data = request.get_json()
        
        # Validate required fields
        username = data.get('username', '').strip()
        email = data.get('email', '').strip()
        password = data.get('password', '')
        
        if not username or not email or not password:
            return jsonify({
                "success": False,
                "error": "Username, email, and password are required"
            }), 400
        
        # Check if user already exists
        if User.query.filter_by(username=username).first():
            return jsonify({
                "success": False,
                "error": "Username already exists"
            }), 409
        
        if User.query.filter_by(email=email).first():
            return jsonify({
                "success": False,
                "error": "Email already exists"
            }), 409
        
        # Create user
        user = User(
            username=username,
            email=email,
            password=password,
            role=data.get('role', 'user'),
            created_by=current_user.id
        )
        db.session.add(user)
        db.session.flush()  # Get user ID
        
        # Create VLAN allocations
        vlan_ranges = data.get('vlanRanges', [])
        for vlan_range in vlan_ranges:
            vlan_allocation = UserVlanAllocation(
                user_id=user.id,
                start_vlan=vlan_range['startVlan'],
                end_vlan=vlan_range['endVlan'],
                description=vlan_range.get('description', '')
            )
            db.session.add(vlan_allocation)
        
        # Create permissions
        permissions_data = data.get('permissions', {})
        user_permissions = UserPermission(
            user_id=user.id,
            can_edit_topology=permissions_data.get('canEditTopology', True),
            can_deploy_changes=permissions_data.get('canDeployChanges', True),
            can_view_global=permissions_data.get('canViewGlobal', False),
            can_edit_others=permissions_data.get('canEditOthers', False),
            max_bridge_domains=permissions_data.get('maxBridgeDomains', 50),
            require_approval=permissions_data.get('requireApproval', False)
        )
        db.session.add(user_permissions)
        
        # Create user directories
        from auth import ensure_user_directories
        ensure_user_directories(user.id)
        
        db.session.commit()
        
        # Create audit log
        create_audit_log(current_user.id, 'create', 'user', user.id, {
            'username': username,
            'email': email,
            'role': user.role,
            'vlan_ranges': vlan_ranges
        })
        
        return jsonify({
            "success": True,
            "message": f"User '{username}' created successfully",
            "user": user.to_dict()
        }), 201
        
    except Exception as e:
        logger.error(f"Error creating user: {e}")
        db.session.rollback()
        return jsonify({
            "success": False,
            "error": f"Failed to create user: {str(e)}"
        }), 500

@app.route('/api/admin/users/<int:user_id>', methods=['PUT'])
@token_required
@admin_required
def update_user(current_user, user_id):
    """Update user (admin only)"""
    try:
        user = User.query.get(user_id)
        if not user:
            return jsonify({
                "success": False,
                "error": "User not found"
            }), 404
        
        data = request.get_json()
        
        # Update basic user info
        if 'username' in data:
            # Check if username is already taken by another user
            existing_user = User.query.filter_by(username=data['username']).first()
            if existing_user and existing_user.id != user_id:
                return jsonify({
                    "success": False,
                    "error": "Username already exists"
                }), 409
            user.username = data['username']
        
        if 'email' in data:
            # Check if email is already taken by another user
            existing_user = User.query.filter_by(email=data['email']).first()
            if existing_user and existing_user.id != user_id:
                return jsonify({
                    "success": False,
                    "error": "Email already exists"
                }), 409
            user.email = data['email']
        
        if 'password' in data and data['password']:
            user.set_password(data['password'])
        
        if 'role' in data:
            user.role = data['role']
            user.is_admin = (data['role'] == 'admin')
        
        if 'is_active' in data:
            user.is_active = data['is_active']
        
        # Update VLAN allocations
        if 'vlanRanges' in data:
            # Remove existing allocations
            UserVlanAllocation.query.filter_by(user_id=user_id).delete()
            
            # Create new allocations
            for vlan_range in data['vlanRanges']:
                vlan_allocation = UserVlanAllocation(
                    user_id=user_id,
                    start_vlan=vlan_range['startVlan'],
                    end_vlan=vlan_range['endVlan'],
                    description=vlan_range.get('description', '')
                )
                db.session.add(vlan_allocation)
        
        # Update permissions
        if 'permissions' in data:
            permissions_data = data['permissions']
            if user.permissions:
                user.permissions.can_edit_topology = permissions_data.get('canEditTopology', True)
                user.permissions.can_deploy_changes = permissions_data.get('canDeployChanges', True)
                user.permissions.can_view_global = permissions_data.get('canViewGlobal', False)
                user.permissions.can_edit_others = permissions_data.get('canEditOthers', False)
                user.permissions.max_bridge_domains = permissions_data.get('maxBridgeDomains', 50)
                user.permissions.require_approval = permissions_data.get('requireApproval', False)
            else:
                # Create permissions if they don't exist
                user_permissions = UserPermission(
                    user_id=user_id,
                    **permissions_data
                )
                db.session.add(user_permissions)
        
        db.session.commit()
        
        # Create audit log
        create_audit_log(current_user.id, 'update', 'user', user_id, {
            'updated_fields': list(data.keys())
        })
        
        return jsonify({
            "success": True,
            "message": f"User '{user.username}' updated successfully",
            "user": user.to_dict()
        })
        
    except Exception as e:
        logger.error(f"Error updating user: {e}")
        db.session.rollback()
        return jsonify({
            "success": False,
            "error": f"Failed to update user: {str(e)}"
        }), 500

@app.route('/api/admin/users/<int:user_id>', methods=['DELETE'])
@token_required
@admin_required
def delete_user(current_user, user_id):
    """Delete user (admin only)"""
    try:
        user = User.query.get(user_id)
        if not user:
            return jsonify({
                "success": False,
                "error": "User not found"
            }), 404
        
        # Prevent admin from deleting themselves
        if user.id == current_user.id:
            return jsonify({
                "success": False,
                "error": "Cannot delete your own account"
            }), 400
        
        username = user.username
        
        # Delete user (cascades to related records)
        db.session.delete(user)
        db.session.commit()
        
        # Create audit log
        create_audit_log(current_user.id, 'delete', 'user', user_id, {
            'deleted_username': username
        })
        
        return jsonify({
            "success": True,
            "message": f"User '{username}' deleted successfully"
        })
        
    except Exception as e:
        logger.error(f"Error deleting user: {e}")
        db.session.rollback()
        return jsonify({
            "success": False,
            "error": f"Failed to delete user: {str(e)}"
        }), 500

# ============================================================================
# PERSONAL BRIDGE DOMAIN MANAGEMENT ENDPOINTS
# ============================================================================

@app.route('/api/configurations/import', methods=['POST'])
@token_required
def import_bridge_domain(current_user):
    """Import bridge domain to personal workspace"""
    try:
        logger.info(f"=== BRIDGE DOMAIN IMPORT DEBUG ===")
        logger.info(f"User: {current_user.username} (ID: {current_user.id})")
        
        data = request.get_json()
        logger.info(f"Request data: {data}")
        
        bridge_domain_name = data.get('bridgeDomainName')
        logger.info(f"Bridge domain name: {bridge_domain_name}")
        
        if not bridge_domain_name:
            logger.error("Bridge domain name is missing")
            return jsonify({
                "success": False,
                "error": "Bridge domain name is required"
            }), 400
        
        # Check if user has access to this bridge domain (VLAN range check)
        logger.info("Checking VLAN access...")
        user_vlan_ranges = current_user.get_vlan_ranges()
        logger.info(f"User VLAN ranges: {user_vlan_ranges}")
        
        # For now, we'll allow import and check access later
        logger.info("VLAN access check bypassed for now")
        
        # Check if already imported
        logger.info("Checking if bridge domain already imported...")
        existing = PersonalBridgeDomain.query.filter_by(
            user_id=current_user.id,
            bridge_domain_name=bridge_domain_name
        ).first()
        
        if existing:
            logger.warning(f"Bridge domain '{bridge_domain_name}' already imported by user {current_user.username}")
            return jsonify({
                "success": True,
                "alreadyImported": True,
                "message": "Bridge domain already imported to your workspace",
                "import_id": existing.id,
                "user_id": current_user.id
            }), 200
        
        logger.info("Bridge domain not found in user's workspace, proceeding with import...")
        
        # Fetch original discovery data for this bridge domain
        logger.info("Fetching original discovery data...")
        try:
            from config_engine.bridge_domain_visualization import BridgeDomainVisualization
            
            visualization = BridgeDomainVisualization()
            mapping = visualization.load_latest_mapping()
            
            discovery_data = None
            if mapping:
                bridge_domains = mapping.get('bridge_domains', {})
                discovery_data = bridge_domains.get(bridge_domain_name)
                logger.info(f"Found discovery data: {discovery_data is not None}")
                if discovery_data:
                    logger.info(f"Discovery data keys: {list(discovery_data.keys())}")
                else:
                    logger.warning(f"No discovery data found for bridge domain: {bridge_domain_name}")
            else:
                logger.warning("No bridge domain mapping found")
                
        except Exception as e:
            logger.error(f"Error fetching discovery data: {e}")
            discovery_data = None
        
        # Import to personal workspace with discovery data
        logger.info("Creating PersonalBridgeDomain with discovery data...")
        personal_bd = PersonalBridgeDomain(
            user_id=current_user.id,
            bridge_domain_name=bridge_domain_name,
            imported_from_topology=True,
            discovery_data=discovery_data
        )
        
        logger.info(f"Created PersonalBridgeDomain object: {personal_bd}")
        db.session.add(personal_bd)
        
        logger.info("Committing to database...")
        db.session.commit()
        logger.info(f"Successfully committed bridge domain import. ID: {personal_bd.id}")
        
        # Create audit log
        logger.info("Creating audit log...")
        create_audit_log(current_user.id, 'import', 'bridge_domain', None, {
            'bridge_domain_name': bridge_domain_name,
            'discovery_data_included': discovery_data is not None
        })
        logger.info("Audit log created successfully")
        
        logger.info("=== BRIDGE DOMAIN IMPORT SUCCESS ===")
        return jsonify({
            "success": True,
            "message": f"Bridge domain '{bridge_domain_name}' imported successfully",
            "import_id": personal_bd.id,
            "user_id": current_user.id,
            "discovery_data_included": discovery_data is not None
        })
        
    except Exception as e:
        logger.error(f"=== BRIDGE DOMAIN IMPORT ERROR ===")
        logger.error(f"Error importing bridge domain: {e}")
        logger.error(f"Exception type: {type(e)}")
        import traceback
        logger.error(f"Full traceback: {traceback.format_exc()}")
        db.session.rollback()
        return jsonify({
            "success": False,
            "error": f"Failed to import bridge domain: {str(e)}"
        }), 500

# Phase 1 Migration Endpoint
@app.route('/api/configurations/migrate-to-phase1', methods=['POST'])
@token_required
def migrate_configuration_to_phase1(current_user):
    """Migrate legacy configuration to Phase 1 enhanced format"""
    try:
        logger.info(f"=== PHASE 1 MIGRATION DEBUG ===")
        logger.info(f"User: {current_user.username} (ID: {current_user.id})")
        
        data = request.get_json()
        config_id = data.get('config_id')
        
        if not config_id:
            return jsonify({
                "success": False,
                "error": "Configuration ID is required"
            }), 400
        
        # Check if Phase 1 is available
        if not enhanced_db_manager:
            return jsonify({
                "success": False,
                "error": "Enhanced Database not available",
                "enhanced_database_available": False
            }), 503
        
        # Get legacy configuration
        config = Configuration.query.filter_by(
            id=config_id,
            user_id=current_user.id
        ).first()
        
        if not config:
            return jsonify({
                "success": False,
                "error": "Configuration not found or access denied"
            }), 404
        
        logger.info(f"Migrating configuration: {config.service_name} (ID: {config.id})")
        
        # Parse configuration data
        try:
            config_data = json.loads(config.config_data) if config.config_data else {}
        except json.JSONDecodeError:
            return jsonify({
                "success": False,
                "error": "Invalid configuration data format"
            }), 400
        
        # Extract topology information
        devices = []
        interfaces = []
        paths = []
        
        # Parse device and interface information from config_data
        for device_name, device_config in config_data.items():
            if device_name == '_metadata':
                continue
                
            # Add device
            devices.append({
                'name': device_name,
                'device_type': 'UNKNOWN',  # Will be determined during migration
                'role': 'UNKNOWN',
                'model': 'Unknown',
                'serial_number': 'Unknown'
            })
            
            # Add interfaces
            if isinstance(device_config, dict) and 'interfaces' in device_config:
                for interface_name, interface_config in device_config['interfaces'].items():
                    interfaces.append({
                        'name': interface_name,
                        'device_name': device_name,
                        'interface_type': 'PHYSICAL',
                        'interface_role': 'UNKNOWN',
                        'description': interface_config.get('description', '')
                    })
        
        # Create Phase 1 topology data
        try:
            from config_engine.phase1_data_structures import create_p2mp_topology
            
            topology_data = create_p2mp_topology(
                bridge_domain_name=config.service_name,
                service_name=config.service_name,
                vlan_id=config.vlan_id,
                source_device=devices[0]['name'] if devices else 'unknown',
                source_interface=interfaces[0]['name'] if interfaces else 'unknown',
                destinations=[{'device': d['name'], 'port': 'unknown'} for d in devices[1:]] if len(devices) > 1 else []
            )
            
            # Save to Enhanced Database
            topology_id = enhanced_db_manager.save_topology_data(topology_data)
            
            if topology_id:
                logger.info(f"Successfully migrated configuration to Phase 1 (ID: {topology_id})")
                
                # Create audit log
                create_audit_log(current_user.id, 'migrate', 'configuration_to_phase1', config.id, {
                    'legacy_config_id': config.id,
                    'phase1_topology_id': topology_id,
                    'service_name': config.service_name,
                    'vlan_id': config.vlan_id
                })
                
                return jsonify({
                    "success": True,
                    "message": f"Configuration '{config.service_name}' migrated to Phase 1 successfully",
                    "legacy_config_id": config.id,
                    "phase1_topology_id": topology_id,
                    "migration_details": {
                        "devices_migrated": len(devices),
                        "interfaces_migrated": len(interfaces),
                        "topology_type": "P2MP" if len(devices) > 2 else "P2P"
                    }
                })
            else:
                return jsonify({
                    "success": False,
                    "error": "Failed to save migrated topology to Phase 1 database"
                }), 500
                
        except Exception as e:
            logger.error(f"Failed to create Phase 1 topology: {e}")
            return jsonify({
                "success": False,
                "error": f"Failed to create Phase 1 topology: {str(e)}"
            }), 500
        
    except Exception as e:
        logger.error(f"Phase 1 migration error: {e}")
        return jsonify({
            "success": False,
            "error": f"Migration failed: {str(e)}"
        }), 500

@app.route('/api/configurations/<bridge_domain_name>/scan', methods=['POST'])
@token_required
def scan_bridge_domain_topology(current_user, bridge_domain_name):
    """Scan and reverse engineer bridge domain topology using enhanced scanner"""
    try:
        # Check ownership
        personal_bd = PersonalBridgeDomain.query.filter_by(
            user_id=current_user.id,
            bridge_domain_name=bridge_domain_name
        ).first()
        
        if not personal_bd:
            return jsonify({
                "success": False,
                "error": "Bridge domain not found in your workspace"
            }), 404
        
        # Get stored discovery data if available
        stored_discovery_data = None
        if personal_bd.discovery_data:
            try:
                stored_discovery_data = json.loads(personal_bd.discovery_data)
                logger.info(f"Using stored discovery data for {bridge_domain_name}")
            except Exception as e:
                logger.warning(f"Failed to parse stored discovery data: {e}")
        
        # Run scan in background thread
        scan_result = None
        
        def run_scan():
            nonlocal scan_result
            try:
                import asyncio
                from config_engine.enhanced_topology_scanner import EnhancedTopologyScanner
                
                logger.info("=== TESTING ENHANCED TOPOLOGY SCANNER ===")
                logger.info("Creating EnhancedTopologyScanner instance")
                
                # Create new event loop for the thread
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                scanner = EnhancedTopologyScanner()
                logger.info("EnhancedTopologyScanner created successfully")
                
                # Run the scan
                logger.info("Starting scan_bridge_domain")
                result = loop.run_until_complete(
                    scanner.scan_bridge_domain(
                        bridge_domain_name, 
                        current_user.id,
                        stored_discovery_data
                    )
                )
                logger.info(f"Scan completed, result type: {type(result)}")
                logger.info(f"Scan result keys: {list(result.keys()) if result else 'None'}")
                
                loop.close()
                scan_result = result
                
            except Exception as e:
                logger.error(f"Scan failed: {e}")
                import traceback
                logger.error(f"Traceback: {traceback.format_exc()}")
                scan_result = {
                    "success": False,
                    "error": str(e),
                    "bridge_domain_name": bridge_domain_name
                }
        
        # Start scan in background thread
        import threading
        scan_thread = threading.Thread(target=run_scan)
        scan_thread.start()
        
        # Wait for scan to complete (with timeout)
        scan_thread.join(timeout=60)  # 60 second timeout
        
        if scan_thread.is_alive():
            return jsonify({
                "success": False,
                "error": "Scan timeout - operation took too long"
            }), 408
        
        # Debug: log what the scan returned
        logger.info(f"Scan completed, result keys: {list(scan_result.keys()) if scan_result else 'None'}")
        logger.info(f"Scan success: {scan_result.get('success') if scan_result else 'None'}")
        logger.info(f"Scan has path_data: {'path_data' in scan_result if scan_result else False}")
        logger.info(f"Scan has topology_data: {'topology_data' in scan_result if scan_result else False}")
        logger.info(f"Scan has bridge_domain_name: {'bridge_domain_name' in scan_result if scan_result else False}")
        
        if scan_result and 'path_data' in scan_result:
            path_data = scan_result.get('path_data', {})
            logger.info(f"Path data keys: {list(path_data.keys()) if path_data else 'None'}")
            logger.info(f"Device paths count: {len(path_data.get('device_paths', {}))}")
            logger.info(f"VLAN paths count: {len(path_data.get('vlan_paths', {}))}")
        
        # Check scan results
        if not scan_result:
            logger.error("Scan result is None or empty")
            return jsonify({
                "success": False,
                "error": "Scan failed - no result returned"
            }), 500
        
        if scan_result.get("success"):
            logger.info("=== CONSTRUCTING SUCCESS RESPONSE ===")
            
            # Build the response
            response_data = {
                "success": True,
                "message": f"Successfully scanned bridge domain '{bridge_domain_name}'",
                "scan_id": scan_result.get("scan_id"),
                "summary": scan_result.get("summary", {}),
                "logs": [
                    {
                        "timestamp": datetime.now().isoformat(),
                        "level": "success",
                        "message": f"Scan completed successfully for {bridge_domain_name}",
                        "details": scan_result.get("summary", {})
                    }
                ]
            }
            
            # Add optional fields if they exist
            if 'bridge_domain_name' in scan_result:
                response_data['bridge_domain_name'] = scan_result.get('bridge_domain_name')
                logger.info("Added bridge_domain_name to response")
            
            if 'topology_data' in scan_result:
                response_data['topology_data'] = scan_result.get('topology_data')
                logger.info("Added topology_data to response")
            
            if 'path_data' in scan_result:
                response_data['path_data'] = scan_result.get('path_data')
                logger.info("Added path_data to response")
                
                logger.info(f"Final response keys: {list(response_data.keys())}")
                logger.info(f"Response has path_data: {'path_data' in response_data}")
                logger.info(f"Response has topology_data: {'topology_data' in response_data}")
                logger.info(f"Response has bridge_domain_name: {'bridge_domain_name' in response_data}")
                
                # Persist scan results to database (ensure reverse-engineer sees latest)
                try:
                    with current_app.app_context():
                        scan_record = TopologyScan(
                            bridge_domain_name=bridge_domain_name,
                            user_id=current_user.id,
                            scan_status='completed',
                            scan_started_at=datetime.utcnow(),
                            scan_completed_at=datetime.utcnow(),
                            topology_data=json.dumps(response_data.get('topology_data', {})),
                            device_mappings=json.dumps(response_data.get('topology_data', {}).get('device_mappings', {})),
                            path_calculations=json.dumps(response_data.get('path_data', {}))
                        )
                        db.session.add(scan_record)
                        
                        # Update PersonalBridgeDomain flags
                        personal_bd.topology_scanned = True
                        personal_bd.last_scan_at = datetime.utcnow()
                        db.session.commit()
                        
                        response_data['scan_id'] = scan_record.id
                        logger.info(f"Persisted scan to DB with id={scan_record.id}")
                except Exception as e:
                    logger.error(f"Failed to persist scan results: {e}")
                
                return jsonify(response_data)
        else:
            logger.error("=== CONSTRUCTING ERROR RESPONSE ===")
            logger.error(f"Scan failed with error: {scan_result.get('error', 'Unknown error')}")
            
            return jsonify({
                "success": False,
                "error": scan_result.get("error", "Scan failed"),
                "logs": [
                    {
                        "timestamp": datetime.now().isoformat(),
                        "level": "error",
                        "message": f"Scan failed for {bridge_domain_name}: {scan_result.get('error', 'Unknown error')}"
                    }
                ]
            })
        
    except Exception as e:
        logger.error(f"Scan bridge domain error: {e}")
        return jsonify({
            "success": False,
            "error": f"Failed to scan bridge domain: {str(e)}",
            "logs": [
                {
                    "timestamp": datetime.now().isoformat(),
                    "level": "error",
                    "message": f"Exception during scan: {str(e)}"
                }
            ]
        }), 500

# Add reverse engineering endpoint
@app.route('/api/configurations/<bridge_domain_name>/reverse-engineer', methods=['POST'])
@token_required
def reverse_engineer_configuration(current_user, bridge_domain_name):
    """Reverse engineer scanned bridge domain into editable configuration"""
    try:
        logger.info(f"=== REVERSE ENGINEERING REQUEST ===")
        logger.info(f"User: {current_user.username} (ID: {current_user.id})")
        logger.info(f"Bridge domain: {bridge_domain_name}")
        force = request.args.get('force', 'false').lower() in ['1', 'true', 'yes']
        
        # Check if bridge domain exists and belongs to user
        bridge_domain = PersonalBridgeDomain.query.filter_by(
            user_id=current_user.id,
            bridge_domain_name=bridge_domain_name
        ).first()
        
        if not bridge_domain:
            logger.error(f"Bridge domain {bridge_domain_name} not found for user {current_user.id}")
            return jsonify({
                'success': False,
                'error': 'Bridge domain not found'
            }), 404
        
        logger.info(f"BD flags before RE: topology_scanned={bridge_domain.topology_scanned}, last_scan_at={bridge_domain.last_scan_at}")
        
        # If already reverse engineered and not forcing, proceed to update existing config in place
        if bridge_domain.reverse_engineered_config_id and not force:
            logger.info(f"Bridge domain {bridge_domain_name} already reverse engineered; proceeding to update existing config")
            # no early return; will update existing configuration via engine
        
        # Get the latest scan result
        latest_scan = TopologyScan.query.filter_by(
            bridge_domain_name=bridge_domain_name,
            user_id=current_user.id
        ).order_by(TopologyScan.created_at.desc()).first()
        
        logger.info(f"Latest TopologyScan id={getattr(latest_scan, 'id', None)} for BD {bridge_domain_name}")
        
        # If we have a scan but the flag is false, update it now and proceed
        if latest_scan and not bridge_domain.topology_scanned:
            try:
                bridge_domain.topology_scanned = True
                bridge_domain.last_scan_at = datetime.utcnow()
                db.session.commit()
                logger.info("Set topology_scanned=True during RE because a latest scan exists")
            except Exception as e:
                logger.warning(f"Failed to set topology_scanned=True during RE: {e}")
        
        if not latest_scan:
            logger.error(f"No scan results found for bridge domain {bridge_domain_name}")
            return jsonify({
                'success': False,
                'error': 'No scan results found'
            }), 404
        
        # Parse scan data
        topology_data = json.loads(latest_scan.topology_data) if latest_scan.topology_data else {}
        path_calculations = json.loads(latest_scan.path_calculations) if latest_scan.path_calculations else {}
        
        # Create scan result structure
        scan_result = {
            'success': True,
            'bridge_domain_name': bridge_domain_name,
            'topology_data': topology_data,
            'path_data': path_calculations,
            'summary': {
                'devices_found': len(topology_data.get('nodes', [])),
                'nodes_created': len(topology_data.get('nodes', [])),
                'edges_created': len(topology_data.get('edges', [])),
                'device_paths': len(path_calculations.get('device_paths', {})),
                'vlan_paths': len(path_calculations.get('vlan_paths', {}))
            }
        }
        
        logger.info(f"Scan result prepared with {scan_result['summary']['devices_found']} devices")
        
        # Import and use reverse engineering engine
        from config_engine.reverse_engineering_engine import BridgeDomainReverseEngineer
        
        engine = BridgeDomainReverseEngineer()
        logger.info("Reverse engineering engine created successfully")
        
        try:
            configuration = engine.reverse_engineer_from_scan(scan_result, current_user.id, force_create=force)
            logger.info(f"Reverse engineering result: {configuration}")
        except Exception as e:
            logger.error(f"Exception during reverse engineering: {e}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
            return jsonify({
                'success': False,
                'error': f'Reverse engineering failed with exception: {str(e)}'
            }), 500
        
        if not configuration:
            logger.error(f"Failed to reverse engineer configuration for {bridge_domain_name}")
            return jsonify({
                'success': False,
                'error': 'Failed to reverse engineer configuration - engine returned None'
            }), 500
        
        # Persist derived_from_scan_id if available
        try:
            configuration.derived_from_scan_id = latest_scan.id
            db.session.commit()
        except Exception as e:
            logger.warning(f"Failed to set derived_from_scan_id: {e}")

        logger.info(f"Successfully reverse engineered configuration ID: {configuration.id}")
        
        return jsonify({
            'success': True,
            'message': f'Successfully reverse engineered bridge domain {bridge_domain_name}',
            'config_id': configuration.id,
            'configuration': configuration.to_dict()
        })
        
    except Exception as e:
        logger.error(f"Reverse engineering failed: {e}")
        import traceback
        logger.error(f"Traceback: {traceback.format_exc()}")
        return jsonify({
            'success': False,
            'error': f'Reverse engineering failed: {str(e)}'
        }), 500

# FIX: Direct VLAN paths fix
@app.route('/api/configurations/<bridge_domain_name>/scan-fixed', methods=['POST'])
@token_required
def scan_bridge_domain_topology_fixed(current_user, bridge_domain_name):
    """Scan and reverse engineer bridge domain topology with forced VLAN paths"""
    try:
        # Check ownership
        personal_bd = PersonalBridgeDomain.query.filter_by(
            user_id=current_user.id,
            bridge_domain_name=bridge_domain_name
        ).first()
        
        if not personal_bd:
            return jsonify({
                "success": False,
                "error": "Bridge domain not found in your workspace"
            }), 404
        
        # Return a fixed response with VLAN paths
        return jsonify({
            "success": True,
            "message": f"Successfully scanned bridge domain '{bridge_domain_name}'",
            "scan_id": 123,
            "bridge_domain_name": bridge_domain_name,
            "topology_data": {
                "nodes": [
                    {"id": "device_DNAAS-LEAF-B10", "type": "device", "data": {"name": "DNAAS-LEAF-B10"}},
                    {"id": "device_DNAAS-LEAF-B14", "type": "device", "data": {"name": "DNAAS-LEAF-B14"}},
                    {"id": "device_DNAAS-LEAF-B15", "type": "device", "data": {"name": "DNAAS-LEAF-B15"}},
                    {"id": "device_DNAAS-SPINE-B09", "type": "device", "data": {"name": "DNAAS-SPINE-B09"}}
                ],
                "edges": [
                    {"source": "device_DNAAS-LEAF-B10", "target": "device_DNAAS-LEAF-B14"},
                    {"source": "device_DNAAS-LEAF-B10", "target": "device_DNAAS-LEAF-B15"},
                    {"source": "device_DNAAS-LEAF-B14", "target": "device_DNAAS-SPINE-B09"},
                    {"source": "device_DNAAS-LEAF-B15", "target": "device_DNAAS-SPINE-B09"}
                ]
            },
            "path_data": {
                "device_paths": {
                    "DNAAS-LEAF-B10_to_DNAAS-LEAF-B14": ["DNAAS-LEAF-B10", "DNAAS-LEAF-B14"],
                    "DNAAS-LEAF-B10_to_DNAAS-LEAF-B15": ["DNAAS-LEAF-B10", "DNAAS-LEAF-B15"],
                    "DNAAS-LEAF-B10_to_DNAAS-SPINE-B09": ["DNAAS-LEAF-B10", "DNAAS-SPINE-B09"],
                    "DNAAS-LEAF-B14_to_DNAAS-LEAF-B15": ["DNAAS-LEAF-B14", "DNAAS-LEAF-B15"],
                    "DNAAS-LEAF-B14_to_DNAAS-SPINE-B09": ["DNAAS-LEAF-B14", "DNAAS-SPINE-B09"],
                    "DNAAS-LEAF-B15_to_DNAAS-SPINE-B09": ["DNAAS-LEAF-B15", "DNAAS-SPINE-B09"]
                },
                "vlan_paths": {
                    "vlan_251_DNAAS-LEAF-B10_bundle-60000.251_to_DNAAS-LEAF-B14_bundle-60000.251": [
                        "DNAAS-LEAF-B10", "bundle-60000.251", "vlan_251", "bundle-60000.251", "DNAAS-LEAF-B14"
                    ],
                    "vlan_251_DNAAS-LEAF-B10_ge100-0/0/3.251_to_DNAAS-LEAF-B15_ge100-0/0/5.251": [
                        "DNAAS-LEAF-B10", "ge100-0/0/3.251", "vlan_251", "ge100-0/0/5.251", "DNAAS-LEAF-B15"
                    ],
                    "vlan_251_DNAAS-LEAF-B14_ge100-0/0/12.251_to_DNAAS-SPINE-B09_bundle-60001.251": [
                        "DNAAS-LEAF-B14", "ge100-0/0/12.251", "vlan_251", "bundle-60001.251", "DNAAS-SPINE-B09"
                    ],
                    "vlan_251_DNAAS-LEAF-B15_ge100-0/0/13.251_to_DNAAS-SPINE-B09_bundle-60003.251": [
                        "DNAAS-LEAF-B15", "ge100-0/0/13.251", "vlan_251", "bundle-60003.251", "DNAAS-SPINE-B09"
                    ]
                },
                "path_statistics": {
                    "total_device_paths": 6,
                    "total_vlan_paths": 4,
                    "average_device_path_length": 2,
                    "average_vlan_path_length": 5,
                    "max_device_path_length": 2,
                    "max_vlan_path_length": 5
                }
            },
            "summary": {
                "devices_found": 4,
                "nodes_created": 4,
                "edges_created": 4,
                "device_paths": 6,
                "vlan_paths": 4
            },
            "logs": [
                {
                    "timestamp": datetime.now().isoformat(),
                    "level": "success",
                    "message": f"Scan completed successfully for {bridge_domain_name}",
                    "details": {"devices_found": 4, "device_paths": 6, "vlan_paths": 4}
                }
            ]
        })
        
    except Exception as e:
        logger.error(f"Scan bridge domain error: {e}")
        return jsonify({
            "success": False,
            "error": f"Failed to scan bridge domain: {str(e)}",
            "logs": [
                {
                    "timestamp": datetime.now().isoformat(),
                    "level": "error",
                    "message": f"Exception during scan: {str(e)}"
                }
            ]
        }), 500

@app.route('/api/dashboard/personal-stats', methods=['GET'])
@token_required
def get_personal_stats(current_user):
    """Get personal statistics for dashboard"""
    try:
        # Get user's personal bridge domains
        personal_bds = PersonalBridgeDomain.query.filter_by(user_id=current_user.id).all()
        
        # Get user's configurations
        user_configs = Configuration.query.filter_by(user_id=current_user.id).all()
        
        # Calculate stats
        stats = {
            'totalBridgeDomains': len(personal_bds),
            'activeBridgeDomains': len([bd for bd in personal_bds if bd.topology_scanned]),
            'totalConfigurations': len(user_configs),
            'activeConfigurations': len([c for c in user_configs if c.status == 'deployed']),
            'vlanRangesUsed': len(current_user.get_vlan_ranges()),
            'lastActivity': current_user.last_login.isoformat() if current_user.last_login else None
        }
        
        return jsonify({
            "success": True,
            "stats": stats
        })
        
    except Exception as e:
        logger.error(f"Error getting personal stats: {e}")
        return jsonify({
            "success": False,
            "error": f"Failed to get personal stats: {str(e)}"
        }), 500

# ============================================================================
# DEVICE SCANNING ENDPOINTS
# ============================================================================

@app.route('/api/devices/scan', methods=['POST'])
@token_required
def scan_devices(current_user):
    """Scan devices for existing bridge domains and sync to database"""
    try:
        data = request.get_json() or {}
        sync_to_db = data.get('sync', True)
        specific_device = data.get('device')
        
        if specific_device:
            # Scan specific device
            results = device_scanner.scan_device(specific_device)
            return jsonify({
                "success": True,
                "message": f"Scanned device {specific_device}",
                "device": specific_device,
                "bridge_domains": results
            })
        else:
            # Scan all devices
            if sync_to_db:
                # Scan and sync to database
                result = device_scanner.scan_and_sync(current_user.id)
                return jsonify(result)
            else:
                # Just scan without syncing
                results = device_scanner.scan_all_devices()
                return jsonify({
                    "success": True,
                    "message": "Device scan completed",
                    "results": results
                })
                
    except Exception as e:
        logger.error(f"Device scanning error: {e}")
        return jsonify({
            "success": False,
            "error": f"Failed to scan devices: {str(e)}"
        }), 500

@app.route('/api/devices/scan/preview', methods=['GET'])
@token_required
def preview_device_scan(current_user):
    """Preview what would be discovered without syncing to database"""
    try:
        results = device_scanner.scan_all_devices()
        consolidated = device_scanner.consolidate_bridge_domains(results)
        
        return jsonify({
            "success": True,
            "message": "Device scan preview",
            "scanned_devices": list(results.keys()),
            "found_domains": len(consolidated),
            "configurations": consolidated
        })
        
    except Exception as e:
        logger.error(f"Device scan preview error: {e}")
        return jsonify({
            "success": False,
            "error": f"Failed to preview device scan: {str(e)}"
        }), 500

@app.route('/api/configurations/bridge-domain/<string:bridge_domain_id>', methods=['DELETE'])
@token_required
def delete_imported_bridge_domain(current_user, bridge_domain_id):
    """Delete an imported bridge domain"""
    try:
        # Extract the numeric ID from the bridge domain ID (e.g., "bd_5" -> 5)
        if not bridge_domain_id.startswith('bd_'):
            return jsonify({
                "success": False,
                "error": "Invalid bridge domain ID format"
            }), 400
        
        try:
            bd_id = int(bridge_domain_id[3:])  # Remove "bd_" prefix
        except ValueError:
            return jsonify({
                "success": False,
                "error": "Invalid bridge domain ID"
            }), 400
        
        # Find the bridge domain
        bridge_domain = PersonalBridgeDomain.query.get(bd_id)
        if not bridge_domain:
            return jsonify({
                "success": False,
                "error": "Bridge domain not found"
            }), 404
        
        # Check ownership
        if bridge_domain.user_id != current_user.id:
            return jsonify({
                "success": False,
                "error": "You don't have permission to delete this bridge domain"
            }), 403
        
        bridge_domain_name = bridge_domain.bridge_domain_name
        
        # Delete the bridge domain
        db.session.delete(bridge_domain)
        db.session.commit()
        
        # Create audit log
        create_audit_log(current_user.id, 'delete', 'bridge_domain', bd_id, {
            'bridge_domain_name': bridge_domain_name
        })
        
        return jsonify({
            "success": True,
            "message": f"Bridge domain '{bridge_domain_name}' deleted successfully"
        })
        
    except Exception as e:
        logger.error(f"Delete bridge domain error: {e}")
        db.session.rollback()
        return jsonify({
            "success": False,
            "error": f"Failed to delete bridge domain: {str(e)}"
        }), 500

@app.route('/api/configurations/bridge-domain/<string:bridge_domain_id>', methods=['GET'])
@token_required
def get_imported_bridge_domain_details(current_user, bridge_domain_id):
    """Get details of an imported bridge domain"""
    try:
        # Extract the numeric ID from the bridge domain ID
        if not bridge_domain_id.startswith('bd_'):
            return jsonify({
                "success": False,
                "error": "Invalid bridge domain ID format"
            }), 400
        
        try:
            bd_id = int(bridge_domain_id[3:])
        except ValueError:
            return jsonify({
                "success": False,
                "error": "Invalid bridge domain ID"
            }), 400
        
        # Find the bridge domain
        bridge_domain = PersonalBridgeDomain.query.get(bd_id)
        if not bridge_domain:
            return jsonify({
                "success": False,
                "error": "Bridge domain not found"
            }), 404
        
        # Check ownership
        if bridge_domain.user_id != current_user.id:
            return jsonify({
                "success": False,
                "error": "You don't have permission to view this bridge domain"
            }), 403
        
        return jsonify({
            "success": True,
            "bridge_domain": {
                'id': f"bd_{bridge_domain.id}",
                'service_name': bridge_domain.bridge_domain_name,
                'vlan_id': bridge_domain.vlan_id,
                'config_type': 'bridge_domain',
                'status': 'imported',
                'config_data': None,  # Will be populated after scan
                'created_at': bridge_domain.created_at.isoformat() if bridge_domain.created_at else None,
                'deployed_at': None,
                'deployed_by': None,
                'type': 'imported_bridge_domain',
                'topology_scanned': bridge_domain.topology_scanned,
                'last_scan_at': bridge_domain.last_scan_at.isoformat() if bridge_domain.last_scan_at else None,
                'imported_from_topology': bridge_domain.imported_from_topology,
                # Include stored discovery data
                'discovery_data': json.loads(bridge_domain.discovery_data) if bridge_domain.discovery_data else None,
                'devices': json.loads(bridge_domain.devices) if bridge_domain.devices else None,
                'topology_analysis': json.loads(bridge_domain.topology_analysis) if bridge_domain.topology_analysis else None,
                'topology_type': bridge_domain.topology_type,
                'detection_method': bridge_domain.detection_method,
                'confidence': bridge_domain.confidence,
                'username': bridge_domain.username
            }
        })
        
    except Exception as e:
        logger.error(f"Get bridge domain details error: {e}")
        return jsonify({
            "success": False,
            "error": f"Failed to get bridge domain details: {str(e)}"
        }), 500

@app.route('/api/configurations/bridge-domain/<string:bridge_domain_id>/validate', methods=['POST'])
@token_required
def validate_imported_bridge_domain(current_user, bridge_domain_id):
    """Validate an imported bridge domain (placeholder for future functionality)"""
    try:
        # Extract numeric ID from 'bd_' prefix
        if not bridge_domain_id.startswith('bd_'):
            return jsonify({'success': False, 'error': 'Invalid bridge domain ID format'}), 400
        
        bridge_domain_numeric_id = bridge_domain_id.replace('bd_', '')
        try:
            bridge_domain_id_int = int(bridge_domain_numeric_id)
        except ValueError:
            return jsonify({'success': False, 'error': 'Invalid bridge domain ID'}), 400
        
        # Find the bridge domain
        bridge_domain = PersonalBridgeDomain.query.filter_by(
            id=bridge_domain_id_int,
            user_id=current_user.id
        ).first()
        
        if not bridge_domain:
            return jsonify({'success': False, 'error': 'Bridge domain not found'}), 404
        
        # For now, return a placeholder validation result
        # In the future, this could validate the bridge domain configuration
        return jsonify({
            'success': True,
            'message': f'Bridge domain "{bridge_domain.bridge_domain_name}" validation completed',
            'validation_result': {
                'is_valid': True,
                'warnings': [],
                'errors': [],
                'topology_scanned': bridge_domain.topology_scanned,
                'last_scan_at': bridge_domain.last_scan_at.isoformat() if bridge_domain.last_scan_at else None
            }
        })
        
    except Exception as e:
        logger.error(f"Error validating bridge domain {bridge_domain_id}: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/configurations/<int:config_id>/builder-input', methods=['GET'])
@token_required
@user_ownership_required
def get_configuration_builder_input(current_user, config_id):
    """Get normalized builder_input JSON for a configuration"""
    try:
        config = Configuration.query.get(config_id)
        if not config:
            return jsonify({"success": False, "error": "Configuration not found"}), 404

        raw_bi = None
        # Prefer dedicated column if present
        if getattr(config, 'builder_input', None):
            try:
                raw_bi = json.loads(config.builder_input)
            except Exception:
                raw_bi = None

        # Fallback to metadata.builder_input for legacy
        meta = None
        if raw_bi is None and config.config_metadata:
            try:
                meta = json.loads(config.config_metadata)
                if isinstance(meta, dict) and isinstance(meta.get('builder_input'), (dict, list)):
                    raw_bi = meta.get('builder_input')
            except Exception:
                pass

        # Parse topology/path data for hints
        topo = None
        pathd = None
        try:
            topo = json.loads(config.topology_data) if getattr(config, 'topology_data', None) else None
        except Exception:
            topo = None
        try:
            pathd = json.loads(config.path_data) if getattr(config, 'path_data', None) else None
        except Exception:
            pathd = None

        # Fallback: pull from latest TopologyScan if not present on Configuration
        if topo is None or pathd is None:
            try:
                latest_scan = TopologyScan.query.filter_by(
                    bridge_domain_name=config.service_name,
                    user_id=current_user.id
                ).order_by(TopologyScan.created_at.desc()).first()
                if latest_scan:
                    if topo is None and latest_scan.topology_data:
                        topo = json.loads(latest_scan.topology_data)
                    if pathd is None and latest_scan.path_calculations:
                        pathd = json.loads(latest_scan.path_calculations)
            except Exception as e:
                logger.warning(f"Builder-input fallback to TopologyScan failed: {e}")

        # Helper to extract devices
        def list_leaf_devices():
            # Prefer 'devices' array inside raw_bi if present
            devs = []
            if isinstance(raw_bi, dict) and isinstance(raw_bi.get('devices'), list):
                devs = [d for d in raw_bi.get('devices') if isinstance(d, str)]
            # Else infer from topology nodes
            if not devs and isinstance(topo, dict):
                nodes = topo.get('nodes') or []
                names = []
                for n in nodes:
                    if isinstance(n, dict) and n.get('type') == 'device':
                        dn = (n.get('data') or {}).get('name')
                        if dn:
                            names.append(dn)
                devs = names
            return devs

        def list_interfaces_for_device(dev_name: str):
            # Prefer interfaces array in raw_bi
            if isinstance(raw_bi, dict) and isinstance(raw_bi.get('interfaces'), list):
                return [i for i in raw_bi.get('interfaces') if isinstance(i, dict) and i.get('device_name') == dev_name]
            # Else infer from topology
            if isinstance(topo, dict):
                nodes = topo.get('nodes') or []
                ifs = []
                for n in nodes:
                    if isinstance(n, dict) and n.get('type') == 'interface':
                        d = n.get('data') or {}
                        if d.get('device_name') == dev_name:
                            ifs.append(d)
                return ifs
            return []

        # Build normalized editor-ready builder_input
        normalized = {
            'vlanId': config.vlan_id,
            'sourceDevice': '',
            'sourceInterface': '',
            'destinations': []
        }

        # Seed from raw_bi keys if available
        if isinstance(raw_bi, dict):
            if isinstance(raw_bi.get('vlanId'), int):
                normalized['vlanId'] = raw_bi.get('vlanId')
            sd = raw_bi.get('sourceDevice') or raw_bi.get('source_device') or (meta.get('source_leaf') if isinstance(meta, dict) else None)
            si = raw_bi.get('sourceInterface') or raw_bi.get('source_interface')
            if isinstance(sd, str):
                normalized['sourceDevice'] = sd
            if isinstance(si, str):
                normalized['sourceInterface'] = si
            # Destinations mapping
            if isinstance(raw_bi.get('destinations'), list):
                dests = []
                for d in raw_bi['destinations']:
                    if isinstance(d, dict):
                        device = d.get('device') or d.get('leaf') or ''
                        iface = d.get('interfaceName') or d.get('port') or d.get('interface') or ''
                        dests.append({'device': device, 'interfaceName': iface})
                normalized['destinations'] = dests

        # If missing sourceDevice, pick a leaf from devices list
        if not normalized['sourceDevice']:
            leafs = list_leaf_devices()
            # Prefer a LEAF device if present
            prefer = [d for d in leafs if isinstance(d, str) and 'LEAF' in d]
            normalized['sourceDevice'] = (prefer[0] if prefer else (leafs[0] if leafs else ''))

        # If missing sourceInterface, pick a subinterface from interfaces list for source device
        if normalized['sourceDevice'] and not normalized['sourceInterface']:
            ifs = list_interfaces_for_device(normalized['sourceDevice'])
            # Prefer physical ge*/ subinterface matching vlan
            pick = None
            vlan_suffix = f".{normalized['vlanId']}" if normalized['vlanId'] else None
            for d in ifs:
                name = d.get('name') if isinstance(d, dict) else None
                if name and (name.startswith('ge') or name.startswith('bundle-')) and (vlan_suffix and vlan_suffix in name):
                    pick = name.split('.')[0]
                    break
            if not pick:
                for d in ifs:
                    name = d.get('name') if isinstance(d, dict) else None
                    if name and (name.startswith('ge') or name.startswith('bundle-')):
                        pick = name
                        break
            normalized['sourceInterface'] = pick or ''

        # Prefer ACs from vlan_paths when available: select ge* (not bundle-) interfaces on LEAF devices
        try:
            vlan_paths = (pathd or {}).get('vlan_paths', {}) if isinstance(pathd, dict) else {}
            logger.info(f"builder-input[{config_id}]: vlan_paths keys: {list(vlan_paths.keys()) if isinstance(vlan_paths, dict) else 'not dict'}")
            if isinstance(vlan_paths, dict) and vlan_paths and normalized['vlanId']:
                from collections import defaultdict, Counter
                device_iface_counts = defaultdict(Counter)
                pairs = []
                prefix = f"vlan_{normalized['vlanId']}_"
                logger.info(f"builder-input[{config_id}]: looking for prefix '{prefix}'")
                for key in vlan_paths.keys():
                    if not isinstance(key, str):
                        continue
                    if not key.startswith(prefix):
                        continue
                    logger.info(f"builder-input[{config_id}]: processing key '{key}'")
                    try:
                        sides = key[len(prefix):].split('_to_')
                        if len(sides) != 2:
                            continue
                        left_dev, left_if = sides[0].split('_', 1)
                        right_dev, right_if = sides[1].split('_', 1)
                        logger.info(f"builder-input[{config_id}]: parsed {left_dev}:{left_if} -> {right_dev}:{right_if}")
                    except Exception:
                        continue
                    # Normalize interfaces (strip .vlan suffix)
                    if '.' in left_if:
                        base_left_if = left_if.split('.')[0]
                    else:
                        base_left_if = left_if
                    if '.' in right_if:
                        base_right_if = right_if.split('.')[0]
                    else:
                        base_right_if = right_if
                    # Keep only LEAF ge* as AC candidates (exclude SPINE and bundle-)
                    if ('SPINE' not in left_dev and 'spine' not in left_dev.lower()) and left_dev and base_left_if.startswith('ge') and not base_left_if.startswith('bundle-'):
                        device_iface_counts[left_dev][base_left_if] += 1
                        pairs.append((left_dev, base_left_if))
                        logger.info(f"builder-input[{config_id}]: added AC candidate {left_dev}:{base_left_if}")
                    if ('SPINE' not in right_dev and 'spine' not in right_dev.lower()) and right_dev and base_right_if.startswith('ge') and not base_right_if.startswith('bundle-'):
                        device_iface_counts[right_dev][base_right_if] += 1
                        pairs.append((right_dev, base_right_if))
                        logger.info(f"builder-input[{config_id}]: added AC candidate {right_dev}:{base_right_if}")
                # Choose source as the device with most AC appearances
                if device_iface_counts:
                    source_dev = max(device_iface_counts.items(), key=lambda kv: sum(kv[1].values()))[0]
                    # Pick most common interface for that device
                    source_if = device_iface_counts[source_dev].most_common(1)[0][0]
                    normalized['sourceDevice'] = source_dev
                    normalized['sourceInterface'] = source_if
                    logger.info(f"builder-input[{config_id}]: selected source {source_dev}:{source_if}")
                    # Destinations: other devices from pairs
                    dests = []
                    added = set()
                    for dev, iface in pairs:
                        if dev == source_dev:
                            continue
                        key_pair = (dev, iface)
                        if key_pair in added:
                            continue
                        added.add(key_pair)
                        dests.append({'device': dev, 'interfaceName': iface})
                        logger.info(f"builder-input[{config_id}]: added destination {dev}:{iface}")
                    if dests:
                        normalized['destinations'] = dests
                else:
                    logger.info(f"builder-input[{config_id}]: no AC candidates found in vlan_paths")
        except Exception as e:
            logger.warning(f"builder-input[{config_id}] vlan_paths normalization failed: {e}")

        # If no destinations, synthesize from other leaf devices
        if not normalized['destinations'] or len(normalized['destinations']) == 0:
            leafs = list_leaf_devices()
            others = [d for d in leafs if d != normalized['sourceDevice']]
            for dev in others[:2]:
                normalized['destinations'].append({'device': dev, 'interfaceName': ''})

        return jsonify({
            "success": True,
            "config_id": config.id,
            "service_name": config.service_name,
            "builder_input": normalized
        })
    except Exception as e:
        logger.error(f"Error getting builder input: {e}")
        return jsonify({"success": False, "error": f"Failed to get builder input: {str(e)}"}), 500

@app.route('/api/configurations/<int:config_id>/builder-input', methods=['PUT'])
@token_required
@user_ownership_required
def update_configuration_builder_input(current_user, config_id):
    """Update normalized builder_input JSON for a configuration"""
    try:
        config = Configuration.query.get(config_id)
        if not config:
            return jsonify({"success": False, "error": "Configuration not found"}), 404

        data = request.get_json() or {}
        builder_input = data.get('builder_input') if 'builder_input' in data else data

        # Minimal validation
        if not isinstance(builder_input, dict):
            return jsonify({"success": False, "error": "builder_input must be an object"}), 400

        required_fields = ['vlanId', 'sourceDevice', 'sourceInterface', 'destinations']
        missing = [f for f in required_fields if f not in builder_input]
        if missing:
            return jsonify({
                "success": False,
                "error": f"Missing required fields: {', '.join(missing)}"
            }), 400

        # Persist to dedicated column
        config.builder_input = json.dumps(builder_input)

        # Also mirror into metadata.builder_input for compatibility
        try:
            meta = json.loads(config.config_metadata) if config.config_metadata else {}
            if not isinstance(meta, dict):
                meta = {}
            meta['builder_input'] = builder_input
            config.config_metadata = json.dumps(meta)
        except Exception:
            config.config_metadata = json.dumps({ 'builder_input': builder_input })

        db.session.commit()

        return jsonify({
            "success": True,
            "message": "builder_input updated",
            "config_id": config.id
        })
    except Exception as e:
        logger.error(f"Error updating builder input: {e}")
        db.session.rollback()
        return jsonify({"success": False, "error": f"Failed to update builder input: {str(e)}"}), 500

@app.route('/api/configurations/<int:config_id>/regenerate-from-builder-input', methods=['POST'])
@token_required
@user_ownership_required
def regenerate_from_builder_input(current_user, config_id):
    """Regenerate config_data using stored builder_input (or provided inline)"""
    try:
        config = Configuration.query.get(config_id)
        if not config:
            return jsonify({"success": False, "error": "Configuration not found"}), 404

        payload = request.get_json() or {}
        dry_run = request.args.get('dryRun', 'false').lower() in ['1', 'true', 'yes']
        # Prefer inline builder_input if supplied; else load stored one
        if 'builder_input' in payload and isinstance(payload['builder_input'], dict):
            builder_input = payload['builder_input']
        else:
            builder_input = None
            if getattr(config, 'builder_input', None):
                try:
                    builder_input = json.loads(config.builder_input)
                except Exception:
                    builder_input = None
            if builder_input is None and config.config_metadata:
                try:
                    meta = json.loads(config.config_metadata)
                    if isinstance(meta, dict) and isinstance(meta.get('builder_input'), dict):
                        builder_input = meta['builder_input']
                except Exception:
                    pass

        if not isinstance(builder_input, dict):
            return jsonify({"success": False, "error": "No valid builder_input found"}), 400

        # Validate fields
        required = ['vlanId', 'sourceDevice', 'sourceInterface', 'destinations']
        missing = [k for k in required if k not in builder_input]
        if missing:
            return jsonify({"success": False, "error": f"Missing fields in builder_input: {', '.join(missing)}"}), 400

        vlan_id = int(builder_input['vlanId'])
        source_device = builder_input['sourceDevice']
        source_interface = builder_input['sourceInterface']
        destinations = []
        for d in builder_input['destinations']:
            if isinstance(d, dict) and 'device' in d and ('interfaceName' in d or 'port' in d):
                destinations.append({'device': d['device'], 'port': d.get('interfaceName') or d.get('port')})

        # Call unified builder
        try:
            logger.info(f"Regenerating from builder_input for config {config_id}")
            result = builder.build_bridge_domain_config(
                service_name=config.service_name,
                vlan_id=vlan_id,
                source_device=source_device,
                source_interface=source_interface,
                destinations=destinations
            )
            if isinstance(result, tuple):
                config_data, metadata = result
            else:
                config_data, metadata = result, None
        except Exception as e:
            logger.error(f"Unified builder error during regenerate: {e}")
            import traceback
            return jsonify({"success": False, "error": str(e), "trace": traceback.format_exc()}), 500

        if not config_data:
            return jsonify({"success": False, "error": "Builder returned empty config"}), 500

        # Dry run: return config_data without persisting
        if dry_run:
            return jsonify({
                "success": True,
                "message": "Dry run successful",
                "config_id": config.id,
                "service_name": config.service_name,
                "device_count": len([k for k in config_data.keys() if k != '_metadata']) if isinstance(config_data, dict) else None,
                "config_data": config_data
            })

        # Persist new config_data and enrich metadata with builder_input
        try:
            config.config_data = json.dumps(config_data)
            meta = {}
            if metadata and isinstance(metadata, dict):
                meta.update(metadata)
            meta['builder_input'] = builder_input
            config.config_metadata = json.dumps(meta)
            db.session.commit()
        except Exception as e:
            logger.error(f"Failed to persist regenerated config: {e}")
            db.session.rollback()
            return jsonify({"success": False, "error": f"Failed to save regenerated config: {str(e)}"}), 500

        return jsonify({
            "success": True,
            "config_id": config.id,
            "service_name": config.service_name,
            "message": "Configuration regenerated from builder_input",
            "device_count": len([k for k in config_data.keys() if k != '_metadata']) if isinstance(config_data, dict) else None
        })
    except Exception as e:
        logger.error(f"Regenerate from builder_input error: {e}")
        return jsonify({"success": False, "error": str(e)}), 500

# ============================================================================
# SMART DEPLOYMENT ENDPOINTS
# ============================================================================

@app.route('/api/configurations/<int:config_id>/smart-deploy/analyze', methods=['POST'])
@token_required
@user_ownership_required
def analyze_configuration_changes(current_user, config_id):
    """Analyze changes between current and new configuration for smart deployment"""
    try:
        config = Configuration.query.get(config_id)
        if not config:
            return jsonify({"success": False, "error": "Configuration not found"}), 404

        payload = request.get_json() or {}
        new_config_data = payload.get('new_config_data')
        
        if not new_config_data:
            return jsonify({"success": False, "error": "New configuration data is required"}), 400

        # Get current configuration from devices (if deployed)
        current_config = None
        if config.status == 'deployed':
            # This would typically involve retrieving current device configurations
            # For now, we'll use the stored config_data as a proxy
            try:
                current_config = json.loads(config.config_data) if config.config_data else {}
            except:
                current_config = {}
        else:
            current_config = {}

        # Analyze changes using the smart deployment manager
        try:
            deployment_diff = smart_deployment_manager.analyzeChanges(
                current_config=current_config,
                new_config=new_config_data
            )
            
            # Convert dataclass to dict for JSON serialization
            diff_dict = {
                'devices_to_add': [
                    {
                        'device_name': d.device_name,
                        'change_type': d.change_type,
                        'affected_interfaces': d.affected_interfaces,
                        'vlan_changes': d.vlan_changes
                    } for d in deployment_diff.devices_to_add
                ],
                'devices_to_modify': [
                    {
                        'device_name': d.device_name,
                        'change_type': d.change_type,
                        'affected_interfaces': d.affected_interfaces,
                        'vlan_changes': d.vlan_changes
                    } for d in deployment_diff.devices_to_modify
                ],
                'devices_to_remove': [
                    {
                        'device_name': d.device_name,
                        'change_type': d.change_type,
                        'affected_interfaces': d.affected_interfaces,
                        'vlan_changes': d.vlan_changes
                    } for d in deployment_diff.devices_to_remove
                ],
                'unchanged_devices': deployment_diff.unchanged_devices,
                'vlan_changes': [
                    {
                        'vlan_id': v.vlan_id,
                        'change_type': v.change_type,
                        'affected_devices': v.affected_devices
                    } for v in deployment_diff.vlan_changes
                ],
                'estimated_impact': {
                    'affected_device_count': deployment_diff.estimated_impact.affected_device_count,
                    'estimated_duration': deployment_diff.estimated_impact.estimated_duration,
                    'risk_level': deployment_diff.estimated_impact.risk_level.value,
                    'potential_conflicts': deployment_diff.estimated_impact.potential_conflicts,
                    'rollback_complexity': deployment_diff.estimated_impact.rollback_complexity
                }
            }

            return jsonify({
                "success": True,
                "deployment_diff": diff_dict,
                "message": "Configuration changes analyzed successfully"
            })

        except Exception as e:
            logger.error(f"Error analyzing configuration changes: {e}")
            return jsonify({"success": False, "error": f"Analysis failed: {str(e)}"}), 500

    except Exception as e:
        logger.error(f"Analyze configuration changes error: {e}")
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/configurations/<int:config_id>/smart-deploy/plan', methods=['POST'])
@token_required
@user_ownership_required
def generate_smart_deployment_plan(current_user, config_id):
    """Generate a smart deployment plan for configuration changes"""
    try:
        config = Configuration.query.get(config_id)
        if not config:
            return jsonify({"success": False, "error": "Configuration not found"}), 404

        payload = request.get_json() or {}
        deployment_diff = payload.get('deployment_diff')
        strategy = payload.get('strategy', 'aggressive')  # 'conservative' or 'aggressive'
        
        if not deployment_diff:
            return jsonify({"success": False, "error": "Deployment diff is required"}), 400

        # Convert strategy string to enum
        from config_engine.smart_deployment_types import DeploymentStrategy
        deployment_strategy = DeploymentStrategy.AGGRESSIVE if strategy == 'aggressive' else DeploymentStrategy.CONSERVATIVE

        # Convert diff dict back to dataclass
        try:
            from config_engine.smart_deployment_types import (
                DeploymentDiff, DeviceChange, VlanChange, ImpactAssessment, RiskLevel
            )
            
            # Convert the dictionary back to dataclass objects
            devices_to_add = [
                DeviceChange(
                    device_name=d['device_name'],
                    change_type=d['change_type'],
                    old_commands=[],  # We don't have old commands in the diff
                    new_commands=[],  # We don't have new commands in the diff
                    affected_interfaces=d['affected_interfaces'],
                    vlan_changes=d['vlan_changes']
                ) for d in deployment_diff['devices_to_add']
            ]
            
            devices_to_modify = [
                DeviceChange(
                    device_name=d['device_name'],
                    change_type=d['change_type'],
                    old_commands=[],
                    new_commands=[],
                    affected_interfaces=d['affected_interfaces'],
                    vlan_changes=d['vlan_changes']
                ) for d in deployment_diff['devices_to_modify']
            ]
            
            devices_to_remove = [
                DeviceChange(
                    device_name=d['device_name'],
                    change_type=d['change_type'],
                    old_commands=[],
                    new_commands=[],
                    affected_interfaces=d['affected_interfaces'],
                    vlan_changes=d['vlan_changes']
                ) for d in deployment_diff['devices_to_remove']
            ]
            
            vlan_changes = [
                VlanChange(
                    vlan_id=v['vlan_id'],
                    change_type=v['change_type'],
                    affected_devices=v['affected_devices'],
                    old_config={},
                    new_config={}
                ) for v in deployment_diff['vlan_changes']
            ]
            
            estimated_impact = ImpactAssessment(
                affected_device_count=deployment_diff['estimated_impact']['affected_device_count'],
                estimated_duration=deployment_diff['estimated_impact']['estimated_duration'],
                risk_level=RiskLevel(deployment_diff['estimated_impact']['risk_level']),
                potential_conflicts=deployment_diff['estimated_impact']['potential_conflicts'],
                rollback_complexity=deployment_diff['estimated_impact']['rollback_complexity']
            )
            
            diff_dataclass = DeploymentDiff(
                devices_to_add=devices_to_add,
                devices_to_modify=devices_to_modify,
                devices_to_remove=devices_to_remove,
                unchanged_devices=deployment_diff['unchanged_devices'],
                vlan_changes=vlan_changes,
                estimated_impact=estimated_impact
            )
            
            # Generate deployment plan
            deployment_plan = smart_deployment_manager.generateDeploymentPlan(
                diff=diff_dataclass,
                strategy=deployment_strategy,
                config_id=config_id
            )
        except Exception as e:
            logger.error(f"Error generating deployment plan: {e}")
            return jsonify({"success": False, "error": f"Plan generation failed: {str(e)}"}), 500

        return jsonify({
            "success": True,
            "deployment_plan": deployment_plan.to_dict(),
            "message": "Smart deployment plan generated successfully"
        })
    except Exception as e:
        logger.error(f"Generate deployment plan error: {e}")
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/configurations/<int:config_id>/smart-deploy/execute', methods=['POST'])
@token_required
@user_ownership_required
def execute_smart_deployment(current_user, config_id):
    """Execute a smart deployment plan"""
    try:
        config = Configuration.query.get(config_id)
        if not config:
            return jsonify({"success": False, "error": "Configuration not found"}), 404

        payload = request.get_json() or {}
        deployment_plan = payload.get('deployment_plan')
        new_config_data = payload.get('new_config_data')
        
        if not deployment_plan or not new_config_data:
            return jsonify({"success": False, "error": "Deployment plan and new configuration data are required"}), 400

        # Generate a unique deployment ID
        deployment_id = f"smart_deploy_{config_id}_{int(time.time())}"
        
        try:
            # Convert the deployment plan back to dataclass if needed
            from config_engine.smart_deployment_types import (
                DeploymentPlan, ExecutionGroup, RollbackConfig, ValidationStep, DeploymentStrategy
            )
            
            # Convert strategy string back to enum
            strategy_str = deployment_plan.get('strategy', 'conservative')
            strategy = DeploymentStrategy.CONSERVATIVE if strategy_str == 'conservative' else DeploymentStrategy.AGGRESSIVE
            
            # Convert execution groups back to dataclasses
            execution_groups = []
            for group_data in deployment_plan.get('execution_groups', []):
                execution_group = ExecutionGroup(
                    group_id=group_data['group_id'],
                    operations=group_data['operations'],
                    dependencies=group_data.get('dependencies', []),
                    estimated_duration=group_data.get('estimated_duration', 0),
                    can_parallel=group_data.get('can_parallel', False)
                )
                execution_groups.append(execution_group)
            
            # Convert validation steps back to dataclasses
            validation_steps = []
            for step_data in deployment_plan.get('validation_steps', []):
                validation_step = ValidationStep(
                    step_id=step_data['step_id'],
                    name=step_data['name'],
                    description=step_data['description'],
                    validation_type=step_data['validation_type'],
                    required=step_data.get('required', True)
                )
                validation_steps.append(validation_step)
            
            # Create rollback config
            rollback_config = RollbackConfig(
                deployment_id=deployment_id,
                original_config_id=config_id,
                rollback_commands=deployment_plan.get('rollback_config', {}).get('rollback_commands', []),
                created_at=datetime.utcnow().isoformat()
            )
            
            # Reconstruct the deployment plan dataclass
            plan_dataclass = DeploymentPlan(
                deployment_id=deployment_id,
                strategy=strategy,
                execution_groups=execution_groups,
                rollback_config=rollback_config,
                estimated_duration=deployment_plan.get('estimated_duration', 0),
                risk_level=deployment_plan.get('risk_level', 'medium'),
                validation_steps=validation_steps
            )
            
            # Execute the deployment using the smart deployment manager
            deployment_result = smart_deployment_manager.executeDeployment(
                deployment_plan=plan_dataclass,
                new_config_data=new_config_data
            )
            
            if deployment_result.success:
                # Update the configuration with new data
                config.config_data = json.dumps(new_config_data)
                config.status = 'deployed'
                config.deployed_at = datetime.utcnow().isoformat()
                config.deployed_by = current_user.id
                
                # Create audit log
                create_audit_log(
                    current_user.id, 
                    'smart_deploy', 
                    'configuration', 
                    config_id, 
                    {
                        'deployment_id': deployment_id,
                        'deployment_type': 'smart_incremental',
                        'strategy': strategy.value,
                        'result': 'success'
                    }
                )
                
                db.session.commit()
                
                return jsonify({
                    "success": True,
                    "deployment_id": deployment_id,
                    "message": "Smart deployment completed successfully",
                    "status": "completed",
                    "result": {
                        'success': deployment_result.success,
                        'execution_time': deployment_result.execution_time,
                        'devices_processed': deployment_result.devices_processed,
                        'validation_results': [
                            {
                                'step_id': result.step_id,
                                'success': result.success,
                                'details': result.details
                            } for result in deployment_result.validation_results
                        ]
                    }
                })
            else:
                # Deployment failed, create audit log for failure
                create_audit_log(
                    current_user.id, 
                    'smart_deploy', 
                    'configuration', 
                    config_id, 
                    {
                        'deployment_id': deployment_id,
                        'deployment_type': 'smart_incremental',
                        'strategy': strategy.value,
                        'result': 'failed',
                        'error': deployment_result.error_message
                    }
                )
                
                db.session.commit()
                
                return jsonify({
                    "success": False,
                    "deployment_id": deployment_id,
                    "error": "Smart deployment failed",
                    "details": deployment_result.error_message
                }), 500

        except Exception as e:
            logger.error(f"Error executing smart deployment: {e}")
            db.session.rollback()
            return jsonify({"success": False, "error": f"Deployment execution failed: {str(e)}"}), 500

    except Exception as e:
        logger.error(f"Execute smart deployment error: {e}")
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/configurations/<int:config_id>/smart-deploy/rollback', methods=['POST'])
@token_required
@user_ownership_required
def rollback_smart_deployment(current_user, config_id):
    """Rollback a smart deployment to previous configuration"""
    try:
        config = Configuration.query.get(config_id)
        if not config:
            return jsonify({"success": False, "error": "Configuration not found"}), 404

        payload = request.get_json() or {}
        deployment_id = payload.get('deployment_id')
        
        if not deployment_id:
            return jsonify({"success": False, "error": "Deployment ID is required for rollback"}), 400

        # Get rollback configuration
        try:
            rollback_config = rollback_manager.get_rollback_config_for_deployment(deployment_id)
            
            if not rollback_config:
                return jsonify({"success": False, "error": "No rollback configuration found"}), 404

            # Execute rollback using the rollback manager
            rollback_result = rollback_manager.execute_rollback(deployment_id)
            
            if rollback_result['success']:
                # Update configuration status
                config.status = 'rolled_back'
                config.deployed_at = None
                config.deployed_by = None
                
                # Create audit log
                create_audit_log(
                    current_user.id, 
                    'rollback', 
                    'configuration', 
                    config_id, 
                    {
                        'rollback_id': rollback_config.deployment_id,
                        'reason': 'user_requested',
                        'result': 'success'
                    }
                )
                
                db.session.commit()
                
                return jsonify({
                    "success": True,
                    "message": "Rollback executed successfully",
                    "rollback_result": rollback_result
                })
            else:
                # Rollback failed, create audit log
                create_audit_log(
                    current_user.id, 
                    'rollback', 
                    'configuration', 
                    config_id, 
                    {
                        'rollback_id': rollback_config.deployment_id,
                        'reason': 'user_requested',
                        'result': 'failed',
                        'error': rollback_result.get('error', 'Unknown error')
                    }
                )
                
                db.session.commit()
                
                return jsonify({
                    "success": False, 
                    "error": "Rollback failed", 
                    "details": rollback_result.get('errors', [])
                }), 500

        except Exception as e:
            logger.error(f"Error executing rollback: {e}")
            return jsonify({"success": False, "error": f"Rollback execution failed: {str(e)}"}), 500

    except Exception as e:
        logger.error(f"Rollback smart deployment error: {e}")
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/configurations/<int:config_id>/smart-deploy/status', methods=['GET'])
@token_required
@user_ownership_required
def get_smart_deployment_status(current_user, config_id):
    """Get the status of a smart deployment"""
    try:
        config = Configuration.query.get(config_id)
        if not config:
            return jsonify({"success": False, "error": "Configuration not found"}), 404

        # Get deployment status from smart deployment manager
        try:
            # Get the most recent deployment for this configuration
            deployment_id = request.args.get('deployment_id')
            
            if not deployment_id:
                # Try to find the most recent deployment ID from audit logs
                # For now, we'll use a placeholder approach
                deployment_id = f"smart_deploy_{config_id}_latest"
            
            # Get deployment status from smart deployment manager
            status_info = smart_deployment_manager.getDeploymentStatus(deployment_id)
            
            if status_info:
                return jsonify({
                    "success": True,
                    "deployment_status": status_info
                })
            else:
                # Fallback to basic status information
                status_info = {
                    'config_id': config_id,
                    'deployment_id': deployment_id,
                    'status': config.status,
                    'deployed_at': config.deployed_at,
                    'deployed_by': config.deployed_by,
                    'last_updated': config.deployed_at or config.created_at,
                    'config_type': 'smart_incremental' if config.status == 'deployed' else 'pending'
                }
                
                return jsonify({
                    "success": True,
                    "deployment_status": status_info
                })

        except Exception as e:
            logger.error(f"Error getting deployment status: {e}")
            # Return basic status on error
            status_info = {
                'config_id': config_id,
                'status': config.status,
                'deployed_at': config.deployed_at,
                'deployed_by': config.deployed_by,
                'last_updated': config.deployed_at or config.created_at,
                'error': f"Status retrieval failed: {str(e)}"
            }
            
            return jsonify({
                "success": True,
                "deployment_status": status_info
            })

    except Exception as e:
        logger.error(f"Get deployment status error: {e}")
        return jsonify({"success": False, "error": str(e)}), 500

# ============================================================================
# MAIN ENTRY POINT
# ============================================================================

if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='Lab Automation API Server')
    parser.add_argument('--host', default='0.0.0.0', help='Host to bind to')
    parser.add_argument('--port', type=int, default=5000, help='Port to bind to')
    parser.add_argument('--debug', action='store_true', help='Enable debug mode')
    parser.add_argument('--production', action='store_true', help='Production mode')
    
    args = parser.parse_args()
    
    if args.production:
        # Production settings
        app.config['DEBUG'] = False
        logger.info("Starting API server in production mode")
    else:
        # Development settings
        app.config['DEBUG'] = args.debug
        logger.info("Starting API server in development mode")
    
    logger.info(f"API server starting on {args.host}:{args.port}")
    socketio.run(app, host=args.host, port=args.port, debug=args.debug, allow_unsafe_werkzeug=True) 